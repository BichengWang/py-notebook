{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79249d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/opt/homebrew/anaconda3/envs/python-notebook/lib/python39.zip', '/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.9', '/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.9/lib-dynload', '', '/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.9/site-packages', '/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.9/site-packages/setuptools/_vendor']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375e3074",
   "metadata": {},
   "source": [
    "# GPU check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f28a40",
   "metadata": {},
   "source": [
    "## Env Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a84e802",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install asitop -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76c4ac7",
   "metadata": {},
   "source": [
    "# Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c030f659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "WARNING:tensorflow:From /var/folders/ls/5qzq87350jz6pv6jwnpg6mkm0000gn/T/ipykernel_35334/3687830407.py:3: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "gpu available: True\n",
      "cuda available: True\n",
      "is cuda min 3: False\n",
      "Metal device set to: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-29 12:18:35.000327: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-29 12:18:35.000416: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2024-09-29 12:18:35.001697: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-29 12:18:35.001707: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2024-09-29 12:18:35.001757: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-29 12:18:35.001763: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple M2\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"device\", tf.config.list_physical_devices('GPU'))\n",
    "gpu_available = tf.test.is_gpu_available()\n",
    "is_cuda_gpu_available = tf.test.is_gpu_available(cuda_only=True)\n",
    "is_cuda_gpu_min_3 = tf.test.is_gpu_available(True, (3,0))\n",
    "print(f'gpu available: {gpu_available}')\n",
    "print(f'cuda available: {is_cuda_gpu_available}')\n",
    "print(f'is cuda min 3: {is_cuda_gpu_min_3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da9ffd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "TensorFlow version: 2.9.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available: \", tf.config.experimental.list_physical_devices('GPU'))\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ed91c80",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:absl:module 'tensorflow_datasets.core' has no attribute 'utils'\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.9/site-packages/tensorflow_datasets/__init__.py\", line 59, in <module>\n",
      "    from tensorflow_datasets import audio\n",
      "  File \"/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.9/site-packages/tensorflow_datasets/audio/__init__.py\", line 19, in <module>\n",
      "    from tensorflow_datasets.audio.commonvoice import CommonVoice\n",
      "  File \"/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.9/site-packages/tensorflow_datasets/audio/commonvoice.py\", line 27, in <module>\n",
      "    import tensorflow_datasets.public_api as tfds\n",
      "  File \"/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.9/site-packages/tensorflow_datasets/public_api.py\", line 57, in <module>\n",
      "    deprecated = core.utils.docs.deprecated(deprecated)\n",
      "AttributeError: module 'tensorflow_datasets.core' has no attribute 'utils'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_datasets' has no attribute 'load'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:7\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow_datasets' has no attribute 'load'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 2min 33s, AMD EPYC 7B13 \n",
    "# 3min 17s, Intel(R) Core(TM) i9-9900K CPU @ 3.60GHz\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "tf.config.list_physical_devices('GPU')\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "\n",
    "def normalize_img(image, label):\n",
    "    \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "    return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "batch_size = 128\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(batch_size)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.batch(batch_size)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu'),\n",
    "  tf.keras.layers.Conv2D(64, kernel_size=(3, 3),\n",
    "                 activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#   tf.keras.layers.Dropout(0.25),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "#   tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=12,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b3edc3",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bca78d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement fbgemm-gpu (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for fbgemm-gpu\u001b[0m\u001b[31m\n",
      "\u001b[0m^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mLooking in links: https://download.pytorch.org/whl/cu120/torch_stable.htmldd\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.13.0+cu120 (from versions: 1.9.0, 1.10.0, 1.10.1, 1.10.2, 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.13.0+cu120\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "\n",
    "!python3 -m pip install -q fbgemm-gpu --index-url https://download.pytorch.org/whl/cu121\n",
    "!python3 -m pip install -q torch torchvision torchaudio torchrec torchmetrics --index-url https://download.pytorch.org/whl/cu121\n",
    "!python3 -m pip install torch==1.13.0+cu120 torchrec==0.1.0 -f https://download.pytorch.org/whl/cu120/torch_stable.htmldd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4949869",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "dlopen(/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.9/site-packages/fbgemm_gpu/fbgemm_gpu_py.so, 0x0006): tried: '/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.9/site-packages/fbgemm_gpu/fbgemm_gpu_py.so' (not a mach-o file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.9/site-packages/fbgemm_gpu/fbgemm_gpu_py.so' (no such file), '/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.9/site-packages/fbgemm_gpu/fbgemm_gpu_py.so' (not a mach-o file)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchrec\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdist\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available())\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.9/site-packages/torchrec/__init__.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#!/usr/bin/env python3\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright (c) Meta Platforms, Inc. and affiliates.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# All rights reserved.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the BSD-style license found in the\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchrec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchrec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquant\u001b[39;00m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchrec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tracer  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.9/site-packages/torchrec/distributed/__init__.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#!/usr/bin/env python3\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright (c) Meta Platforms, Inc. and affiliates.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# All rights reserved.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the BSD-style license found in the\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchrec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_parallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistributedModelParallel  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchrec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain_pipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     TrainPipeline,\n\u001b[1;32m     11\u001b[0m     TrainPipelineBase,\n\u001b[1;32m     12\u001b[0m     TrainPipelineSparseDist,\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchrec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     Awaitable,\n\u001b[1;32m     16\u001b[0m     NoWait,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     ShardingEnv,\n\u001b[1;32m     23\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.9/site-packages/torchrec/distributed/model_parallel.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _IncompatibleKeys\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistributedDataParallel\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchrec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddingbag\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     18\u001b[0m     EmbeddingBagCollectionSharder,\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchrec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplanner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     21\u001b[0m     EmbeddingShardingPlanner,\n\u001b[1;32m     22\u001b[0m     sharder_name,\n\u001b[1;32m     23\u001b[0m     Topology,\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchrec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquant_embeddingbag\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QuantEmbeddingBagCollectionSharder\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.9/site-packages/torchrec/distributed/embeddingbag.py:28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _IncompatibleKeys\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchrec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcw_sharding\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CwEmbeddingSharding\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchrec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdp_sharding\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DpEmbeddingSharding\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchrec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membedding_sharding\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     31\u001b[0m     EmbeddingSharding,\n\u001b[1;32m     32\u001b[0m     SparseFeaturesListAwaitable,\n\u001b[1;32m     33\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.9/site-packages/torchrec/distributed/cw_sharding.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdist\u001b[39;00m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfbgemm_gpu\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpermute_pooled_embedding_modules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PermutePooledEmbeddings\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchrec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membedding_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     14\u001b[0m     ShardedEmbeddingTable,\n\u001b[1;32m     15\u001b[0m     EmbeddingComputeKernel,\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchrec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtw_sharding\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TwEmbeddingSharding, TwPooledEmbeddingDist\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.9/site-packages/fbgemm_gpu/__init__.py:12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdirname\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;18;43m__file__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfbgemm_gpu_py.so\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# __init__.py is only used in OSS\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Use existence to check if fbgemm_gpu_py.so has already been loaded\u001b[39;00m\n\u001b[1;32m     16\u001b[0m open_source: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.9/site-packages/torch/_ops.py:1347\u001b[0m, in \u001b[0;36m_Ops.load_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m   1342\u001b[0m path \u001b[38;5;241m=\u001b[39m _utils_internal\u001b[38;5;241m.\u001b[39mresolve_library_path(path)\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dl_open_guard():\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;66;03m# Import the shared library into the process, thus running its\u001b[39;00m\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;66;03m# static (global) initialization code in order to register custom\u001b[39;00m\n\u001b[1;32m   1346\u001b[0m     \u001b[38;5;66;03m# operators with the JIT.\u001b[39;00m\n\u001b[0;32m-> 1347\u001b[0m     \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_libraries\u001b[38;5;241m.\u001b[39madd(path)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.9/ctypes/__init__.py:374\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 374\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[0;31mOSError\u001b[0m: dlopen(/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.9/site-packages/fbgemm_gpu/fbgemm_gpu_py.so, 0x0006): tried: '/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.9/site-packages/fbgemm_gpu/fbgemm_gpu_py.so' (not a mach-o file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.9/site-packages/fbgemm_gpu/fbgemm_gpu_py.so' (no such file), '/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.9/site-packages/fbgemm_gpu/fbgemm_gpu_py.so' (not a mach-o file)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import os\n",
    "import torchrec\n",
    "import torch.distributed as dist\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "    print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "    print('__CUDA Device Name:',torch.cuda.get_device_name(0))\n",
    "    print('__CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)\n",
    "\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"29500\"\n",
    "\n",
    "# Note - you will need a V100 or A100 to run tutorial as as!\n",
    "# If using an older GPU (such as colab free K80),\n",
    "# you will need to compile fbgemm with the appripriate CUDA architecture nccl\n",
    "# or run with \"gloo\" on CPUs \n",
    "dist.init_process_group(backend=\"gloo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00d31617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 100\n",
      "Iteration: 200\n",
      "Iteration: 300\n",
      "Iteration: 400\n",
      "Iteration: 500\n",
      "Iteration: 600\n",
      "Iteration: 700\n",
      "Iteration: 800\n",
      "Iteration: 900\n",
      "CPU times: user 164 ms, sys: 95.3 ms, total: 260 ms\n",
      "Wall time: 430 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 500 ms in Quadro RTX 5000\n",
    "# 600 ms in MPS m2\n",
    "# 12900 ms Intel(R) Xeon(R) Gold 5218 CPU @ 2.30GHz\n",
    "# 35800 ms Intel(R) Xeon(R) Silver 4214R CPU @ 2.40GHz\n",
    "# 21700 ms AMD EPYC 7B13\n",
    "# 13400 ms Intel(R) Core(TM) i9-9900K CPU @ 3.60GHz\n",
    "\n",
    "import torch\n",
    "\n",
    "# Function to perform stress test on GPU\n",
    "def stress_test_gpu(iterations=1000, tensor_size=(1024, 1024), device=torch.device('mps')):\n",
    "    for i in range(iterations):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iteration: {i}\")\n",
    "        x = torch.rand(tensor_size, device=device)\n",
    "        y = torch.rand(tensor_size, device=device)\n",
    "        z = x * y\n",
    "        del x, y, z\n",
    "\n",
    "# Perform stress test\n",
    "stress_test_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01139b32",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torchrec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ebc \u001b[38;5;241m=\u001b[39m \u001b[43mtorchrec\u001b[49m\u001b[38;5;241m.\u001b[39mEmbeddingBagCollection(\n\u001b[1;32m      2\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     tables\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m      4\u001b[0m         torchrec\u001b[38;5;241m.\u001b[39mEmbeddingBagConfig(\n\u001b[1;32m      5\u001b[0m             name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproduct_table\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m             embedding_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m      7\u001b[0m             num_embeddings\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4096\u001b[39m,\n\u001b[1;32m      8\u001b[0m             feature_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproduct\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      9\u001b[0m             pooling\u001b[38;5;241m=\u001b[39mtorchrec\u001b[38;5;241m.\u001b[39mPoolingType\u001b[38;5;241m.\u001b[39mSUM,\n\u001b[1;32m     10\u001b[0m         ),\n\u001b[1;32m     11\u001b[0m         torchrec\u001b[38;5;241m.\u001b[39mEmbeddingBagConfig(\n\u001b[1;32m     12\u001b[0m             name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_table\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m             embedding_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m     14\u001b[0m             num_embeddings\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4096\u001b[39m,\n\u001b[1;32m     15\u001b[0m             feature_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     16\u001b[0m             pooling\u001b[38;5;241m=\u001b[39mtorchrec\u001b[38;5;241m.\u001b[39mPoolingType\u001b[38;5;241m.\u001b[39mSUM,\n\u001b[1;32m     17\u001b[0m         )\n\u001b[1;32m     18\u001b[0m     ]\n\u001b[1;32m     19\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torchrec' is not defined"
     ]
    }
   ],
   "source": [
    "ebc = torchrec.EmbeddingBagCollection(\n",
    "    device=\"meta\",\n",
    "    tables=[\n",
    "        torchrec.EmbeddingBagConfig(\n",
    "            name=\"product_table\",\n",
    "            embedding_dim=64,\n",
    "            num_embeddings=4096,\n",
    "            feature_names=[\"product\"],\n",
    "            pooling=torchrec.PoolingType.SUM,\n",
    "        ),\n",
    "        torchrec.EmbeddingBagConfig(\n",
    "            name=\"user_table\",\n",
    "            embedding_dim=64,\n",
    "            num_embeddings=4096,\n",
    "            feature_names=[\"user\"],\n",
    "            pooling=torchrec.PoolingType.SUM,\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5790c6e2",
   "metadata": {},
   "source": [
    "## PyTorch M1 GPU Test\n",
    "https://zhuanlan.zhihu.com/p/522534035"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18f6527d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, ort, mps, xla, lazy, vulkan, meta, hpu, privateuseone device type at start of device string: gpu",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, ort, mps, xla, lazy, vulkan, meta, hpu, privateuseone device type at start of device string: gpu"
     ]
    }
   ],
   "source": [
    "x = torch.ones((1024 * 12, 1024 * 12), dtype=torch.float32,device='mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a70a259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n",
      "CPU times: user 4.3 ms, sys: 7.35 ms, total: 11.7 ms\n",
      "Wall time: 11.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00, -5.9605e-08,  4.4703e-08],\n",
       "        [-1.1921e-07,  0.0000e+00,  1.1921e-07],\n",
       "        [-2.9802e-08,  0.0000e+00,  0.0000e+00]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "print(device)\n",
    "N = 3\n",
    "\n",
    "A = torch.rand([N,N],dtype=torch.float32)*2 - 1\n",
    "B = torch.rand([N,N],dtype=torch.float32)*5 - 2.5\n",
    "\n",
    "C = A @ B\n",
    "a = A.numpy().astype(np.float32)\n",
    "b = B.numpy().astype(np.float32)\n",
    "c = a @ b\n",
    "C.numpy() - c\n",
    "device = torch.device('mps')\n",
    "\n",
    "aa = A.to(device)\n",
    "bb = B.to(device)\n",
    "cc = aa @ bb\n",
    "CC = cc.cpu().numpy()\n",
    "\n",
    "cc.cpu() - C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f39e9e2",
   "metadata": {},
   "source": [
    "### PyTorch CPU to GPU\n",
    "https://juejin.cn/post/7137891506777489416   \n",
    "https://nni.readthedocs.io/en/stable/tutorials/pruning_bert_glue.html   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6498752f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Could not run 'aten::empty.memory_format' with arguments from the 'MPS' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::empty.memory_format' is only available for these backends: [Dense, FPGA, Conjugate, Negative, ZeroTensor, VmapMode, FuncTorchGradWrapper, Functionalize, MPS, IPU, UNKNOWN_TENSOR_TYPE_ID, QuantizedXPU, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, SparseCPU, SparseCUDA, SparseHIP, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, SparseXPU, UNKNOWN_TENSOR_TYPE_ID, SparseVE, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, NestedTensorCUDA, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:37386 [kernel]\nCUDA: registered at aten/src/ATen/RegisterCUDA.cpp:51977 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:31637 [kernel]\nQuantizedCPU: registered at aten/src/ATen/RegisterQuantizedCPU.cpp:1294 [kernel]\nQuantizedCUDA: registered at aten/src/ATen/RegisterQuantizedCUDA.cpp:546 [kernel]\nMkldnnCPU: registered at aten/src/ATen/RegisterMkldnnCPU.cpp:690 [kernel]\nSparseCPU: registered at aten/src/ATen/RegisterSparseCPU.cpp:1858 [kernel]\nSparseCUDA: registered at aten/src/ATen/RegisterSparseCUDA.cpp:2018 [kernel]\nSparseCsrCPU: registered at aten/src/ATen/RegisterSparseCsrCPU.cpp:1507 [kernel]\nSparseCsrCUDA: registered at aten/src/ATen/RegisterSparseCsrCUDA.cpp:1657 [kernel]\nBackendSelect: registered at aten/src/ATen/RegisterBackendSelect.cpp:726 [kernel]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:133 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: fallthrough registered at ../aten/src/ATen/ConjugateFallback.cpp:22 [kernel]\nNegative: fallthrough registered at ../aten/src/ATen/native/NegateFallback.cpp:22 [kernel]\nZeroTensor: fallthrough registered at ../aten/src/ATen/ZeroTensorFallback.cpp:90 [kernel]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nUNKNOWN_TENSOR_TYPE_ID: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradMPS: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradIPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nUNKNOWN_TENSOR_TYPE_ID: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_2.cpp:14069 [kernel]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:481 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFunctionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:89 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:137 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# device = torch.device(\"cuda:0\")\u001b[39;00m\n\u001b[1;32m      5\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mresnet18()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Could not run 'aten::empty.memory_format' with arguments from the 'MPS' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::empty.memory_format' is only available for these backends: [Dense, FPGA, Conjugate, Negative, ZeroTensor, VmapMode, FuncTorchGradWrapper, Functionalize, MPS, IPU, UNKNOWN_TENSOR_TYPE_ID, QuantizedXPU, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, SparseCPU, SparseCUDA, SparseHIP, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, SparseXPU, UNKNOWN_TENSOR_TYPE_ID, SparseVE, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, NestedTensorCUDA, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:37386 [kernel]\nCUDA: registered at aten/src/ATen/RegisterCUDA.cpp:51977 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:31637 [kernel]\nQuantizedCPU: registered at aten/src/ATen/RegisterQuantizedCPU.cpp:1294 [kernel]\nQuantizedCUDA: registered at aten/src/ATen/RegisterQuantizedCUDA.cpp:546 [kernel]\nMkldnnCPU: registered at aten/src/ATen/RegisterMkldnnCPU.cpp:690 [kernel]\nSparseCPU: registered at aten/src/ATen/RegisterSparseCPU.cpp:1858 [kernel]\nSparseCUDA: registered at aten/src/ATen/RegisterSparseCUDA.cpp:2018 [kernel]\nSparseCsrCPU: registered at aten/src/ATen/RegisterSparseCsrCPU.cpp:1507 [kernel]\nSparseCsrCUDA: registered at aten/src/ATen/RegisterSparseCsrCUDA.cpp:1657 [kernel]\nBackendSelect: registered at aten/src/ATen/RegisterBackendSelect.cpp:726 [kernel]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:133 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: fallthrough registered at ../aten/src/ATen/ConjugateFallback.cpp:22 [kernel]\nNegative: fallthrough registered at ../aten/src/ATen/native/NegateFallback.cpp:22 [kernel]\nZeroTensor: fallthrough registered at ../aten/src/ATen/ZeroTensorFallback.cpp:90 [kernel]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nUNKNOWN_TENSOR_TYPE_ID: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradMPS: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradIPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nUNKNOWN_TENSOR_TYPE_ID: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_2.cpp:14069 [kernel]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:481 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFunctionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:89 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:137 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# device = torch.device(\"cuda:0\")\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "x = torch.randn(32, 32, device=device)\n",
    "model = torchvision.models.resnet18().to(device)\n",
    "\n",
    "print(x.device)\n",
    "print(next(model.parameters()).device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c24f19",
   "metadata": {},
   "source": [
    "#### M1 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5f9efb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae566c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_mode=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d06094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import *\n",
    "from torch.optim import *\n",
    "from torch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813dcae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "# used to save GLUE data\n",
    "data_dir = Path(f'./data')\n",
    "data_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77b1d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Callable, Dict\n",
    "\n",
    "pretrained_model_name_or_path = 'bert-base-uncased'\n",
    "task_name = 'mnli'\n",
    "experiment_id = 'pruning_bert_mnli'\n",
    "\n",
    "# heads_num and layers_num should align with pretrained_model_name_or_path\n",
    "heads_num = 12\n",
    "layers_num = 12\n",
    "\n",
    "# used to save the experiment log\n",
    "log_dir = Path(f'./pruning_log/{pretrained_model_name_or_path}/{task_name}/{experiment_id}')\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# used to save the finetuned model and share between different experiemnts with same pretrained_model_name_or_path and task_name\n",
    "model_dir = Path(f'./models/{pretrained_model_name_or_path}/{task_name}')\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# used to save GLUE data\n",
    "data_dir = Path(f'./data')\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# set seed\n",
    "from transformers import set_seed\n",
    "set_seed(1024)\n",
    "\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01ad651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7627b70231d64f1bafcc2a95d585cb0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5cde59b01140b494ed1a81b2a8df53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129157ba30e543089271962560561096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c654ab5514d5490bbe58c4fdef0a7568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074eb5b622df45e28d257ed435990509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/28.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b4fe96174694c53908320bfd4c4e80e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/28.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85727c7ab9bc475fb81fbd06f5d3e7d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/27.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset glue/mnli to /Users/bicheng.wang/MyFiles/Projects/python/python-notebook/test/data/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b8a6dd10d2d480b86d1f85fa5c4ba1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/313M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation_matched split:   0%|          | 0/9815 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation_mismatched split:   0%|          | 0/9832 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_matched split:   0%|          | 0/9796 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_mismatched split:   0%|          | 0/9847 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset glue downloaded and prepared to /Users/bicheng.wang/MyFiles/Projects/python/python-notebook/test/data/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "260a5f5d954744a6a989ffbbc0649ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/392702 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9815 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9832 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizerFast, DataCollatorWithPadding\n",
    "\n",
    "task_to_keys = {\n",
    "    'cola': ('sentence', None),\n",
    "    'mnli': ('premise', 'hypothesis'),\n",
    "    'mrpc': ('sentence1', 'sentence2'),\n",
    "    'qnli': ('question', 'sentence'),\n",
    "    'qqp': ('question1', 'question2'),\n",
    "    'rte': ('sentence1', 'sentence2'),\n",
    "    'sst2': ('sentence', None),\n",
    "    'stsb': ('sentence1', 'sentence2'),\n",
    "    'wnli': ('sentence1', 'sentence2'),\n",
    "}\n",
    "\n",
    "def prepare_dataloaders(cache_dir=data_dir, train_batch_size=32, eval_batch_size=32):\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path)\n",
    "    sentence1_key, sentence2_key = task_to_keys[task_name]\n",
    "    data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "    # used to preprocess the raw data\n",
    "    def preprocess_function(examples):\n",
    "        # Tokenize the texts\n",
    "        args = (\n",
    "            (examples[sentence1_key],) if sentence2_key is None else (examples[sentence1_key], examples[sentence2_key])\n",
    "        )\n",
    "        result = tokenizer(*args, padding=False, max_length=128, truncation=True)\n",
    "\n",
    "        if 'label' in examples:\n",
    "            # In all cases, rename the column to labels because the model will expect that.\n",
    "            result['labels'] = examples['label']\n",
    "        return result\n",
    "\n",
    "    raw_datasets = load_dataset('glue', task_name, cache_dir=cache_dir)\n",
    "    for key in list(raw_datasets.keys()):\n",
    "        if 'test' in key:\n",
    "            raw_datasets.pop(key)\n",
    "\n",
    "    processed_datasets = raw_datasets.map(preprocess_function, batched=True,\n",
    "                                          remove_columns=raw_datasets['train'].column_names)\n",
    "\n",
    "    train_dataset = processed_datasets['train']\n",
    "    if task_name == 'mnli':\n",
    "        validation_datasets = {\n",
    "            'validation_matched': processed_datasets['validation_matched'],\n",
    "            'validation_mismatched': processed_datasets['validation_mismatched']\n",
    "        }\n",
    "    else:\n",
    "        validation_datasets = {\n",
    "            'validation': processed_datasets['validation']\n",
    "        }\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, shuffle=True, collate_fn=data_collator, batch_size=train_batch_size)\n",
    "    validation_dataloaders = {\n",
    "        val_name: DataLoader(val_dataset, collate_fn=data_collator, batch_size=eval_batch_size) \\\n",
    "            for val_name, val_dataset in validation_datasets.items()\n",
    "    }\n",
    "\n",
    "    return train_dataloader, validation_dataloaders\n",
    "\n",
    "\n",
    "train_dataloader, validation_dataloaders = prepare_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb04bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import time\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_metric\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "\n",
    "def training(model: torch.nn.Module,\n",
    "             optimizer: torch.optim.Optimizer,\n",
    "             criterion: Callable[[torch.Tensor, torch.Tensor], torch.Tensor],\n",
    "             lr_scheduler: torch.optim.lr_scheduler._LRScheduler = None,\n",
    "             max_steps: int = None,\n",
    "             max_epochs: int = None,\n",
    "             train_dataloader: DataLoader = None,\n",
    "             distillation: bool = False,\n",
    "             teacher_model: torch.nn.Module = None,\n",
    "             distil_func: Callable = None,\n",
    "             log_path: str = Path(log_dir) / 'training.log',\n",
    "             save_best_model: bool = False,\n",
    "             save_path: str = None,\n",
    "             evaluation_func: Callable = None,\n",
    "             eval_per_steps: int = 1000,\n",
    "             device=None):\n",
    "\n",
    "    assert train_dataloader is not None\n",
    "\n",
    "    model.train()\n",
    "    if teacher_model is not None:\n",
    "        teacher_model.eval()\n",
    "    current_step = 0\n",
    "    best_result = 0\n",
    "\n",
    "    total_epochs = max_steps // len(train_dataloader) + 1 if max_steps else max_epochs if max_epochs else 3\n",
    "    total_steps = max_steps if max_steps else total_epochs * len(train_dataloader)\n",
    "\n",
    "    print(f'Training {total_epochs} epochs, {total_steps} steps...')\n",
    "\n",
    "    for current_epoch in range(total_epochs):\n",
    "        for batch in train_dataloader:\n",
    "            if current_step >= total_steps:\n",
    "                return\n",
    "            batch.to(device)\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            if distillation:\n",
    "                assert teacher_model is not None\n",
    "                with torch.no_grad():\n",
    "                    teacher_outputs = teacher_model(**batch)\n",
    "                distil_loss = distil_func(outputs, teacher_outputs)\n",
    "                loss = 0.1 * loss + 0.9 * distil_loss\n",
    "\n",
    "            loss = criterion(loss, None)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # per step schedule\n",
    "            if lr_scheduler:\n",
    "                lr_scheduler.step()\n",
    "\n",
    "            current_step += 1\n",
    "\n",
    "            if current_step % eval_per_steps == 0 or current_step % len(train_dataloader) == 0:\n",
    "                result = evaluation_func(model) if evaluation_func else None\n",
    "                with (log_path).open('a+') as f:\n",
    "                    msg = '[{}] Epoch {}, Step {}: {}\\n'.format(time.asctime(time.localtime(time.time())), current_epoch, current_step, result)\n",
    "                    f.write(msg)\n",
    "                # if it's the best model, save it.\n",
    "                if save_best_model and (result is None or best_result < result['default']):\n",
    "                    assert save_path is not None\n",
    "                    torch.save(model.state_dict(), save_path)\n",
    "                    best_result = None if result is None else result['default']\n",
    "\n",
    "\n",
    "def distil_loss_func(stu_outputs: SequenceClassifierOutput, tea_outputs: SequenceClassifierOutput, encoder_layer_idxs=[]):\n",
    "    encoder_hidden_state_loss = []\n",
    "    for i, idx in enumerate(encoder_layer_idxs[:-1]):\n",
    "        encoder_hidden_state_loss.append(F.mse_loss(stu_outputs.hidden_states[i], tea_outputs.hidden_states[idx]))\n",
    "    logits_loss = F.kl_div(F.log_softmax(stu_outputs.logits / 2, dim=-1), F.softmax(tea_outputs.logits / 2, dim=-1), reduction='batchmean') * (2 ** 2)\n",
    "\n",
    "    distil_loss = 0\n",
    "    for loss in encoder_hidden_state_loss:\n",
    "        distil_loss += loss\n",
    "    distil_loss += logits_loss\n",
    "    return distil_loss\n",
    "\n",
    "\n",
    "def evaluation(model: torch.nn.Module, validation_dataloaders: Dict[str, DataLoader] = None, device=None):\n",
    "    assert validation_dataloaders is not None\n",
    "    training = model.training\n",
    "    model.eval()\n",
    "\n",
    "    is_regression = task_name == 'stsb'\n",
    "    metric = load_metric('glue', task_name)\n",
    "\n",
    "    result = {}\n",
    "    default_result = 0\n",
    "    for val_name, validation_dataloader in validation_dataloaders.items():\n",
    "        for batch in validation_dataloader:\n",
    "            batch.to(device)\n",
    "            outputs = model(**batch)\n",
    "            predictions = outputs.logits.argmax(dim=-1) if not is_regression else outputs.logits.squeeze()\n",
    "            metric.add_batch(\n",
    "                predictions=predictions,\n",
    "                references=batch['labels'],\n",
    "            )\n",
    "        result[val_name] = metric.compute()\n",
    "        default_result += result[val_name].get('f1', result[val_name].get('accuracy', 0))\n",
    "    result['default'] = default_result / len(result)\n",
    "\n",
    "    model.train(training)\n",
    "    return result\n",
    "\n",
    "\n",
    "evaluation_func = functools.partial(evaluation, validation_dataloaders=validation_dataloaders, device=device)\n",
    "\n",
    "\n",
    "def fake_criterion(loss, _):\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e87974b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "643af036372249fd9502aeb71141de9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dev_mode' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 38\u001b[0m\n\u001b[1;32m     32\u001b[0m         training(finetuned_model, optimizer, fake_criterion, lr_scheduler\u001b[38;5;241m=\u001b[39mlr_scheduler,\n\u001b[1;32m     33\u001b[0m                  max_epochs\u001b[38;5;241m=\u001b[39mtraining_epochs, train_dataloader\u001b[38;5;241m=\u001b[39mtrain_dataloader, log_path\u001b[38;5;241m=\u001b[39mlog_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinetuning_on_downstream.log\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     34\u001b[0m                  save_best_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, save_path\u001b[38;5;241m=\u001b[39mfinetuned_model_state_path, evaluation_func\u001b[38;5;241m=\u001b[39mevaluation_func, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m finetuned_model\n\u001b[0;32m---> 38\u001b[0m finetuned_model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_finetuned_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[62], line 21\u001b[0m, in \u001b[0;36mcreate_finetuned_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     finetuned_model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(finetuned_model_state_path, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     20\u001b[0m     finetuned_model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mdev_mode\u001b[49m:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dev_mode' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "\n",
    "def create_pretrained_model():\n",
    "    is_regression = task_name == 'stsb'\n",
    "    num_labels = 1 if is_regression else (3 if task_name == 'mnli' else 2)\n",
    "    model = BertForSequenceClassification.from_pretrained(pretrained_model_name_or_path, num_labels=num_labels)\n",
    "    model.bert.config.output_hidden_states = True\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_finetuned_model():\n",
    "    finetuned_model = create_pretrained_model()\n",
    "    finetuned_model_state_path = Path(model_dir) / 'finetuned_model_state.pth'\n",
    "\n",
    "    if finetuned_model_state_path.exists():\n",
    "        finetuned_model.load_state_dict(torch.load(finetuned_model_state_path, map_location='cpu'))\n",
    "        finetuned_model.to(device)\n",
    "    elif dev_mode:\n",
    "        pass\n",
    "    else:\n",
    "        steps_per_epoch = len(train_dataloader)\n",
    "        training_epochs = 3\n",
    "        optimizer = Adam(finetuned_model.parameters(), lr=3e-5, eps=1e-8)\n",
    "\n",
    "        def lr_lambda(current_step: int):\n",
    "            return max(0.0, float(training_epochs * steps_per_epoch - current_step) / float(training_epochs * steps_per_epoch))\n",
    "\n",
    "        lr_scheduler = LambdaLR(optimizer, lr_lambda)\n",
    "        training(finetuned_model, optimizer, fake_criterion, lr_scheduler=lr_scheduler,\n",
    "                 max_epochs=training_epochs, train_dataloader=train_dataloader, log_path=log_dir / 'finetuning_on_downstream.log',\n",
    "                 save_best_model=True, save_path=finetuned_model_state_path, evaluation_func=evaluation_func, device=device)\n",
    "    return finetuned_model\n",
    "\n",
    "\n",
    "finetuned_model = create_finetuned_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98837a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = len(train_dataloader)\n",
    "\n",
    "# Set training steps/epochs for pruning.\n",
    "\n",
    "if not dev_mode:\n",
    "    total_epochs = 4\n",
    "    total_steps = total_epochs * steps_per_epoch\n",
    "    warmup_steps = 1 * steps_per_epoch\n",
    "    cooldown_steps = 1 * steps_per_epoch\n",
    "else:\n",
    "    total_epochs = 1\n",
    "    total_steps = 3\n",
    "    warmup_steps = 1\n",
    "    cooldown_steps = 1\n",
    "\n",
    "# Initialize evaluator used by MovementPruner.\n",
    "\n",
    "import nni\n",
    "from nni.algorithms.compression.v2.pytorch import TorchEvaluator\n",
    "\n",
    "movement_training = functools.partial(training, train_dataloader=train_dataloader,\n",
    "                                      log_path=log_dir / 'movement_pruning.log',\n",
    "                                      evaluation_func=evaluation_func, device=device)\n",
    "traced_optimizer = nni.trace(Adam)(finetuned_model.parameters(), lr=3e-5, eps=1e-8)\n",
    "\n",
    "def lr_lambda(current_step: int):\n",
    "    if current_step < warmup_steps:\n",
    "        return float(current_step) / warmup_steps\n",
    "    return max(0.0, float(total_steps - current_step) / float(total_steps - warmup_steps))\n",
    "\n",
    "traced_scheduler = nni.trace(LambdaLR)(traced_optimizer, lr_lambda)\n",
    "evaluator = TorchEvaluator(movement_training, traced_optimizer, fake_criterion, traced_scheduler)\n",
    "\n",
    "# Apply block-soft-movement pruning on attention layers.\n",
    "# Note that block sparse is introduced by `sparse_granularity='auto'`, and only support `bert`, `bart`, `t5` right now.\n",
    "\n",
    "from nni.compression.pytorch.pruning import MovementPruner\n",
    "\n",
    "config_list = [{\n",
    "    'op_types': ['Linear'],\n",
    "    'op_partial_names': ['bert.encoder.layer.{}.attention'.format(i) for i in range(layers_num)],\n",
    "    'sparsity': 0.1\n",
    "}]\n",
    "\n",
    "pruner = MovementPruner(model=finetuned_model,\n",
    "                        config_list=config_list,\n",
    "                        evaluator=evaluator,\n",
    "                        training_epochs=total_epochs,\n",
    "                        training_steps=total_steps,\n",
    "                        warm_up_step=warmup_steps,\n",
    "                        cool_down_beginning_step=total_steps - cooldown_steps,\n",
    "                        regular_scale=10,\n",
    "                        movement_mode='soft',\n",
    "                        sparse_granularity='auto')\n",
    "_, attention_masks = pruner.compress()\n",
    "pruner.show_pruned_weights()\n",
    "\n",
    "torch.save(attention_masks, Path(log_dir) / 'attention_masks.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796d730c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:22\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'loss'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import transformers\n",
    "\n",
    "model=transformers.AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels=2)\n",
    "\n",
    "optimizer = pytorch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "num_epochs = 1\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = transformers.get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "\n",
    "device = 'mps'\n",
    "model.to(device)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "        if i>10:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e24b88",
   "metadata": {},
   "source": [
    "#### M1 CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d60222",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AdamW' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:3\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AdamW' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model=AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels=2)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "num_epochs = 1\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "device = 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "        if i>10:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6b1392",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n",
      "CPU times: user 4.61 s, sys: 1.48 s, total: 6.08 s\n",
      "Wall time: 3.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "# Load BERT tokenizer and model\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Set up input data\n",
    "input_text = [\"This is a positive sentence.\", \"This is a negative sentence.\"]\n",
    "labels = [1, 0]\n",
    "\n",
    "# Tokenize input data\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "for text in input_text:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,\n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 64,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt'\n",
    "                   )\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert input data to tensors\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Set up optimizer and training parameters\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "epochs = 5\n",
    "batch_size = 2\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(input_ids), batch_size):\n",
    "        input_batch = input_ids[i:i+batch_size]\n",
    "        mask_batch = attention_masks[i:i+batch_size]\n",
    "        label_batch = labels[i:i+batch_size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_batch, attention_mask=mask_batch, labels=label_batch)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluate the model\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    input_ids = input_ids.to(model.device)\n",
    "    attention_masks = attention_masks.to(model.device)\n",
    "    labels = labels.to(model.device)\n",
    "\n",
    "    outputs = model(input_ids, attention_mask=attention_masks, labels=labels)\n",
    "    loss = outputs.loss\n",
    "    logits = outputs.logits\n",
    "\n",
    "    predicted_labels = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496e18b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/Users/bicheng.wang/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf8c5abd8844e90999edd5c0b99dd5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.94 s, sys: 417 ms, total: 3.36 s\n",
      "Wall time: 5.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "\n",
    "# Load the IMDB dataset\n",
    "dataset = load_dataset('imdb')\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(dataset['train']['text'], dataset['train']['label'], test_size=0.99, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c48752b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load BERT tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Tokenize input data\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True)\n",
    "\n",
    "# Convert input data to tensors\n",
    "train_inputs = {key: torch.tensor(val) for key, val in train_encodings.items()}\n",
    "train_labels = torch.tensor(train_labels)\n",
    "test_inputs = {key: torch.tensor(val) for key, val in test_encodings.items()}\n",
    "test_labels = torch.tensor(test_labels)\n",
    "\n",
    "# Set up optimizer and training parameters\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "epochs = 1\n",
    "batch_size = 64\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c165049d",
   "metadata": {},
   "source": [
    "#### Progress Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3560a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 100/100 [00:00<00:00, 629775.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# pip install tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "# works on any iterable, including cursors.\n",
    "# for iterables with len(), no need to specify 'total'.\n",
    "from tqdm import tqdm\n",
    "my_list = list(range(100))\n",
    "with tqdm(total=len(my_list)) as pbar:\n",
    "    for x in my_list:\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46dd18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4f6825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 3\n",
      "{'train': 1000, 'test': 100, 'batch_size': 10}\n"
     ]
    }
   ],
   "source": [
    "subsample = {'train': 1000, 'test': 100, 'batch_size': 10}\n",
    "print(\"total:\", len(dataset['']))\n",
    "print(subsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60ab600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train\n",
      "start epochs\n",
      "start evaluation\n",
      "[0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "CPU times: user 9.76 s, sys: 4.89 s, total: 14.7 s\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"start train\")\n",
    "# Train the model\n",
    "model.train()\n",
    "\n",
    "print(\"start epochs\")\n",
    "# with tqdm(total=epochs*range(0, len(train_labels[0:64]), batch_size)) as pbar:\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(train_labels[:subsample['train']]), subsample['batch_size']):\n",
    "        inputs = {key: val[i:i+batch_size] for key, val in train_inputs.items()}\n",
    "        labels = train_labels[i:i+batch_size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(**inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "#             pbar.update(1)\n",
    "\n",
    "print(\"start evaluation\")\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\n",
    "    inputs = {key: val[:subsample['test']].to(device) for key, val in test_inputs.items()}\n",
    "    labels = test_labels[:subsample['test']].to(device)\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "predicted_labels = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271913e9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/x3/6vwymvgx6mn4vymkfwd_jr340000gn/T/ipykernel_25513/2581333291.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "/var/folders/x3/6vwymvgx6mn4vymkfwd_jr340000gn/T/ipykernel_25513/2581333291.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_labels = torch.tensor(test_labels)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load BERT tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Tokenize input data\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True)\n",
    "\n",
    "# Convert input data to tensors\n",
    "train_inputs = {key: torch.tensor(val) for key, val in train_encodings.items()}\n",
    "train_labels = torch.tensor(train_labels)\n",
    "test_inputs = {key: torch.tensor(val) for key, val in test_encodings.items()}\n",
    "test_labels = torch.tensor(test_labels)\n",
    "\n",
    "# Set up optimizer and training parameters\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "epochs = 1\n",
    "batch_size = 64\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f573121b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train\n",
      "start epochs\n",
      "start evaluation\n",
      "[1 1 0 1 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 1 1 0 0 1 0\n",
      " 1 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1\n",
      " 1 0 1 0 1 0 0 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0]\n",
      "CPU times: user 34min 32s, sys: 13min 50s, total: 48min 22s\n",
      "Wall time: 16min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"start train\")\n",
    "# Train the model\n",
    "model.train()\n",
    "\n",
    "print(\"start epochs\")\n",
    "# with tqdm(total=epochs*range(0, len(train_labels[0:64]), batch_size)) as pbar:\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(train_labels[:subsample['train']]), subsample['batch_size']):\n",
    "        inputs = {key: val[i:i+batch_size] for key, val in train_inputs.items()}\n",
    "        labels = train_labels[i:i+batch_size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(**inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "#             pbar.update(1)\n",
    "\n",
    "print(\"start evaluation\")\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\n",
    "    inputs = {key: val[:subsample['test']].to(device) for key, val in test_inputs.items()}\n",
    "    labels = test_labels[:subsample['test']].to(device)\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "predicted_labels = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3001479",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.device(\"mps\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
