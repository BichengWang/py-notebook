{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["found_layers:{'model.embed_tokens.': False, 'model.layers.0.': False, 'model.layers.1.': False, 'model.layers.2.': False, 'model.layers.3.': False, 'model.layers.4.': False, 'model.layers.5.': False, 'model.layers.6.': False, 'model.layers.7.': False, 'model.layers.8.': False, 'model.layers.9.': False, 'model.layers.10.': False, 'model.layers.11.': False, 'model.layers.12.': False, 'model.layers.13.': False, 'model.layers.14.': False, 'model.layers.15.': False, 'model.layers.16.': False, 'model.layers.17.': False, 'model.layers.18.': False, 'model.layers.19.': False, 'model.layers.20.': False, 'model.layers.21.': False, 'model.layers.22.': False, 'model.layers.23.': False, 'model.layers.24.': False, 'model.layers.25.': False, 'model.layers.26.': False, 'model.layers.27.': False, 'model.layers.28.': False, 'model.layers.29.': False, 'model.layers.30.': False, 'model.layers.31.': False, 'model.layers.32.': False, 'model.layers.33.': False, 'model.layers.34.': False, 'model.layers.35.': False, 'model.layers.36.': False, 'model.layers.37.': False, 'model.layers.38.': False, 'model.layers.39.': False, 'model.layers.40.': False, 'model.layers.41.': False, 'model.layers.42.': False, 'model.layers.43.': False, 'model.layers.44.': False, 'model.layers.45.': False, 'model.layers.46.': False, 'model.layers.47.': False, 'model.layers.48.': False, 'model.layers.49.': False, 'model.layers.50.': False, 'model.layers.51.': False, 'model.layers.52.': False, 'model.layers.53.': False, 'model.layers.54.': False, 'model.layers.55.': False, 'model.layers.56.': False, 'model.layers.57.': False, 'model.layers.58.': False, 'model.layers.59.': False, 'model.layers.60.': False, 'model.layers.61.': False, 'model.layers.62.': False, 'model.layers.63.': False, 'model.layers.64.': False, 'model.layers.65.': False, 'model.layers.66.': False, 'model.layers.67.': False, 'model.layers.68.': False, 'model.layers.69.': False, 'model.layers.70.': False, 'model.layers.71.': False, 'model.layers.72.': False, 'model.layers.73.': False, 'model.layers.74.': False, 'model.layers.75.': False, 'model.layers.76.': False, 'model.layers.77.': False, 'model.layers.78.': False, 'model.layers.79.': False, 'model.norm.': False, 'lm_head.': False}\n","some layer splits found, some are not, re-save all layers in case there's some corruptions.\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/83 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Loading shard 1/30\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"ename":"FileNotFoundError","evalue":"No such file or directory: \"/Users/bichengwang/.cache/huggingface/hub/models--v2ray--Llama-3-70B/snapshots/cfc88c331bbe5371d8ffc3477878ee22793c2463/model-00001-of-00030.safetensors\"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mairllm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModel\n\u001b[1;32m      3\u001b[0m MAX_LENGTH \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mv2ray/Llama-3-70B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m input_text \u001b[38;5;241m=\u001b[39m [        \n\u001b[1;32m      6\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhat is the capital of United States?\u001b[39m\u001b[38;5;124m'\u001b[39m    \n\u001b[1;32m      7\u001b[0m ]\n\u001b[1;32m      8\u001b[0m input_tokens \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtokenizer(input_text,    \n\u001b[1;32m      9\u001b[0m   return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,     \n\u001b[1;32m     10\u001b[0m   return_attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,     \n\u001b[1;32m     11\u001b[0m   truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,     \n\u001b[1;32m     12\u001b[0m   max_length\u001b[38;5;241m=\u001b[39mMAX_LENGTH,     \n\u001b[1;32m     13\u001b[0m   padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","File \u001b[0;32m/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.8/site-packages/airllm/auto_model.py:49\u001b[0m, in \u001b[0;36mAutoModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pretrained\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_on_mac_os:\n\u001b[0;32m---> 49\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mAirLLMLlamaMlx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     module, \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m AutoModel\u001b[38;5;241m.\u001b[39mget_module_class(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     52\u001b[0m     module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(module)\n","File \u001b[0;32m/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.8/site-packages/airllm/airllm_llama_mlx.py:224\u001b[0m, in \u001b[0;36mAirLLMLlamaMlx.__init__\u001b[0;34m(self, model_local_path_or_repo_id, device, dtype, max_seq_len, layer_shards_saving_path, profiling_mode, compression, hf_token, prefetching, test_nonlayered, show_memory_util, delete_original)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleast_available \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_available \u001b[38;5;241m=\u001b[39m psutil\u001b[38;5;241m.\u001b[39mvirtual_memory()\u001b[38;5;241m.\u001b[39mavailable \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1024\u001b[39m\n\u001b[0;32m--> 224\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_local_path, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint_path \u001b[38;5;241m=\u001b[39m \u001b[43mfind_or_create_local_splitted_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_local_path_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m                                                                                 \u001b[49m\u001b[43mlayer_shards_saving_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m                                                                                 \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m                                                                                 \u001b[49m\u001b[43mlayer_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_names_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m                                                                                 \u001b[49m\u001b[43mhf_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m                                                                                 \u001b[49m\u001b[43mdelete_original\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelete_original\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hf_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_local_path, token\u001b[38;5;241m=\u001b[39mhf_token, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[0;32m/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.8/site-packages/airllm/utils.py:382\u001b[0m, in \u001b[0;36mfind_or_create_local_splitted_path\u001b[0;34m(model_local_path_or_repo_id, layer_shards_saving_path, compression, layer_names, hf_token, delete_original)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03mhf_cache_path = huggingface_hub.snapshot_download(model_local_path_or_repo_id, token=hf_token, allow_patterns=\"model.safetensors.index.json\")\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03mif len(glob(str(Path(hf_cache_path) / \"model.safetensors.index.json\"))) > 0:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m                                                      token=hf_token)\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;66;03m#assert os.path.exists(Path(hf_cache_path) / 'pytorch_model.bin.index.json') or \\\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;66;03m#       os.path.exists(Path(hf_cache_path) / 'model.safetensors.index.json'), \\\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m#       f\"{hf_cache_path}/pytorch_model.bin.index.json or {hf_cache_path}/model.safetensors.index.json should exists.\"\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# if splitted_model subdir exists under cache use it, otherwise split and save\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Path(hf_cache_path), \u001b[43msplit_and_save_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhf_cache_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_shards_saving_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mdelete_original\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelete_original\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_local_path_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhf_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_token\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.8/site-packages/airllm/utils.py:297\u001b[0m, in \u001b[0;36msplit_and_save_layers\u001b[0;34m(checkpoint_path, layer_shards_saving_path, splitted_model_dir_name, compression, layer_names, delete_original, repo_id, hf_token)\u001b[0m\n\u001b[1;32m    295\u001b[0m         state_dict\u001b[38;5;241m.\u001b[39mupdate(torch\u001b[38;5;241m.\u001b[39mload(to_load, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 297\u001b[0m         state_dict\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_load\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# Get layer state dict\u001b[39;00m\n\u001b[1;32m    301\u001b[0m layer_state_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m([(k, v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m state_dict\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m.\u001b[39mstartswith(layer)])\n","File \u001b[0;32m/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.8/site-packages/safetensors/torch.py:311\u001b[0m, in \u001b[0;36mload_file\u001b[0;34m(filename, device)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;124;03mLoads a safetensors file into torch format.\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03m```\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    310\u001b[0m result \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msafe_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    313\u001b[0m         result[k] \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mget_tensor(k)\n","\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: \"/Users/bichengwang/.cache/huggingface/hub/models--v2ray--Llama-3-70B/snapshots/cfc88c331bbe5371d8ffc3477878ee22793c2463/model-00001-of-00030.safetensors\""]}],"source":["from airllm import AutoModel\n","\n","MAX_LENGTH = 128\n","model = AutoModel.from_pretrained(\"v2ray/Llama-3-70B\")\n","input_text = [        \n","  'What is the capital of United States?'    \n","]\n","input_tokens = model.tokenizer(input_text,    \n","  return_tensors=\"pt\",     \n","  return_attention_mask=False,     \n","  truncation=True,     \n","  max_length=MAX_LENGTH,     \n","  padding=False)\n","\n","generation_output = model.generate(    \n","  input_tokens['input_ids'].cuda(),     \n","  max_new_tokens=20,    \n","  use_cache=True,    \n","  return_dict_in_generate=True)\n","\n","output = model.tokenizer.decode(generation_output.sequences[0])\n","print(output)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"python-notebook","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"}},"nbformat":4,"nbformat_minor":2}
