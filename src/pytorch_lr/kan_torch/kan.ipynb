{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dsw/snapshots/20e8c12f-8092-4d5c-8aa1-02ed823a3db5/python310/lib/python3.10/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2895.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/dsw/snapshots/20e8c12f-8092-4d5c-8aa1-02ed823a3db5/python310/lib/python3.10/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([40000])) that is different to the input size (torch.Size([40000, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.213651418685913\n",
      "Epoch 100, Loss: 1.0010777711868286\n",
      "Epoch 200, Loss: 1.0001885890960693\n",
      "Epoch 300, Loss: 1.0000379085540771\n",
      "Epoch 400, Loss: 0.9999948740005493\n",
      "Epoch 500, Loss: 0.9999809861183167\n",
      "Epoch 600, Loss: 0.999976634979248\n",
      "Epoch 700, Loss: 0.9999752640724182\n",
      "Epoch 800, Loss: 0.9999750256538391\n",
      "Epoch 900, Loss: 0.9999750256538391\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# Define the univariate functions\n",
    "class UniVariateFunction(nn.Module):\n",
    "    def __init__(self, output_size):\n",
    "        super(UniVariateFunction, self).__init__()\n",
    "        self.linear = nn.Linear(1, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return torch.sin(x) # Using sin as an activation function\n",
    "\n",
    "# Define the KAN Model\n",
    "class KAN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KAN, self).__init__()\n",
    "        self.phi = nn.ModuleList([UniVariateFunction(1) for _ in range(2)]) # phi functions for x and y\n",
    "        self.Phi = nn.Linear(2, 1) # Phi function to combine outputs\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1, x2 = x[:, 0], x[:, 1]\n",
    "        x1 = self.phi[0](x1.view(-1, 1))\n",
    "        x2 = self.phi[1](x2.view(-1, 1))\n",
    "        out = torch.cat((x1, x2), dim=1)\n",
    "        out = self.Phi(out)\n",
    "        return out\n",
    "\n",
    "# Generate sample data\n",
    "x = torch.linspace(-np.pi, np.pi, 200)\n",
    "y = torch.linspace(-np.pi, np.pi, 200)\n",
    "X, Y = torch.meshgrid(x, y)\n",
    "Z = torch.sin(X) + torch.cos(Y)\n",
    "\n",
    "# Prepare inputs and model\n",
    "inputs = torch.stack([X.flatten(), Y.flatten()], dim=1)\n",
    "model = KAN()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, Z.flatten())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
