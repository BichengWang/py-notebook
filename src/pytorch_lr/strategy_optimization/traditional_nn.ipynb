{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b07b8fec",
   "metadata": {},
   "source": [
    "## Strategy optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e231c2d0",
   "metadata": {},
   "source": [
    "this is traditional strategy optimizer which enough to handle most cases of basic trading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d4c17a",
   "metadata": {},
   "source": [
    "### Directly Optimization Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e9f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input -> strategy(input, hyper) -> output\n",
    "# input hyper -> result by input in loss function -> output\n",
    "# eg. reward = a * 2 + b * 5 + c * 3 and a + b + c = 10. ideal result is [2, 5, 3] \n",
    "# output = [theta1, theta2, theta3]\n",
    "# loss = output1...3 -> loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f2ca00b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ls/5qzq87350jz6pv6jwnpg6mkm0000gn/T/ipykernel_31004/526140221.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  a, b, c = model(torch.tensor(x_dummy))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized values - a: 3.8143, b: 6.0970, c: 0.0905\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the neural network\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.a = nn.Linear(hidden_size, 1)\n",
    "        self.b = nn.Linear(hidden_size, 1)\n",
    "        self.c = nn.Linear(hidden_size, 1)\n",
    "\n",
    "        self.a_slope = nn.Parameter(torch.tensor(1.0))\n",
    "        self.a_intercept = nn.Parameter(torch.tensor(0.0))\n",
    "        self.b_slope = nn.Parameter(torch.tensor(1.0))\n",
    "        self.b_intercept = nn.Parameter(torch.tensor(0.0))\n",
    "        self.c_slope = nn.Parameter(torch.tensor(1.0))\n",
    "        self.c_intercept = nn.Parameter(torch.tensor(0.0))\n",
    "        self.relu= nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        # ao, bo, co = self.a(x), self.b(x), self.c(x)\n",
    "        # return ao, bo, co\n",
    "        a_base, b_base, c_base = x[:, 0], x[:, 1], x[:, 2]\n",
    "        a = self.a_slope * a_base + self.a_intercept\n",
    "        b = self.b_slope * b_base + self.b_intercept\n",
    "        c = self.c_slope * c_base + self.c_intercept\n",
    "        return a, b, c\n",
    "\n",
    "# Objective function\n",
    "def loss1(a, b, c):\n",
    "    return -(a * 2 + b * 5 + c * 3).mean()\n",
    "\n",
    "def loss2(a, b, c):\n",
    "    return (1000. * (a + b + c - 10) ** 2).mean()\n",
    "\n",
    "def loss3(a, b, c):\n",
    "    penalty = torch.relu(-a) + torch.relu(-b) + torch.relu(-c)\n",
    "    return penalty.mean() * 1000.  # Large penalty to enforce non-negativity\n",
    "\n",
    "# Initialize the model\n",
    "model = SimpleNet(1, 128)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    x_dummy = torch.zeros(100, 1)\n",
    "    a, b, c = model(torch.tensor(x_dummy))\n",
    "    #  = outputs[0][0], outputs[0][1], outputs[0][2]\n",
    "    loss = loss1(a, b, c) + loss2(a, b, c) + loss3(a, b, c)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # if (epoch + 1) % 100 == 0:\n",
    "        # print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}, a: {a.item():.4f}, b: {b.item():.4f}, c: {c.item():.4f}')\n",
    "\n",
    "# Final optimized values\n",
    "a_opt, b_opt, c_opt = model(torch.tensor([[0.0]]))\n",
    "print(f'Optimized values - a: {a_opt.item():.4f}, b: {b_opt.item():.4f}, c: {c_opt.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d2a23443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Combined Loss: -35.9946, Objective Loss: -36.1386, Constraint Loss: 0.1440, Penalty: 0.0000, a: 1.2982, b: 3.7364, c: 4.9534\n",
      "Optimized values - a: 1.3030, b: 3.7480, c: 4.9679\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the encoder-decoder model\n",
    "class EncoderDecoderModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, latent_size):\n",
    "        super(EncoderDecoderModel, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, latent_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 3)  # Output 3 values for a, b, and c\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        outputs = self.decoder(latent)\n",
    "        a, b, c = outputs[:, 0], outputs[:, 1], outputs[:, 2]\n",
    "        return a, b, c\n",
    "\n",
    "# Objective function\n",
    "def loss1(a, b, c):\n",
    "    return -(a * 2 + b * 5 + c * 3).mean()\n",
    "\n",
    "def loss2(a, b, c):\n",
    "    return ((a + b + c - 10) ** 2).mean() * 1000.\n",
    "\n",
    "def loss3(a, b, c):\n",
    "    penalty = torch.relu(-a) + torch.relu(-b) + torch.relu(-c)\n",
    "    return penalty.mean() * 1000.  # Large penalty to enforce non-negativity\n",
    "\n",
    "# Initialize the model\n",
    "input_size = 1  # Dummy input size, since we're directly optimizing a, b, and c\n",
    "hidden_size = 10\n",
    "latent_size = 5\n",
    "model = EncoderDecoderModel(input_size, hidden_size, latent_size)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "batch_size = 100\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Dummy input for the batch (all ones to simulate intercept learning)\n",
    "    x_dummy = torch.ones(batch_size, input_size)\n",
    "    \n",
    "    # Forward pass\n",
    "    a, b, c = model(x_dummy)\n",
    "    \n",
    "    # Compute losses\n",
    "    obj_loss = loss1(a, b, c)\n",
    "    const_loss = loss2(a, b, c)\n",
    "    non_neg_penalty = loss3(a, b, c)\n",
    "    \n",
    "    # Combine losses with weights\n",
    "    combined_loss = obj_loss + const_loss + non_neg_penalty\n",
    "    combined_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Combined Loss: {combined_loss.item():.4f}, Objective Loss: {obj_loss.item():.4f}, Constraint Loss: {const_loss.item():.4f}, Penalty: {non_neg_penalty.item():.4f}, a: {a.mean().item():.4f}, b: {b.mean().item():.4f}, c: {c.mean().item():.4f}')\n",
    "\n",
    "# Final optimized values (using a single input to get final values)\n",
    "x_dummy = torch.ones(1, input_size)  # Single input to get final values\n",
    "a_opt, b_opt, c_opt = model(x_dummy)\n",
    "print(f'Optimized values - a: {a_opt.item():.4f}, b: {b_opt.item():.4f}, c: {c_opt.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d0938275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/10000], Combined Loss: -23.5286, Objective Loss: -34.0993, Constraint Loss: 10.5707, Penalty: 0.0000, a: 3.0835, b: 3.4372, c: 3.5821\n",
      "Epoch [200/10000], Combined Loss: -33.7676, Objective Loss: -33.7729, Constraint Loss: 0.0054, Penalty: 0.0000, a: 3.0488, b: 3.4074, c: 3.5461\n",
      "Epoch [300/10000], Combined Loss: -33.7813, Objective Loss: -33.7841, Constraint Loss: 0.0028, Penalty: 0.0000, a: 3.0447, b: 3.4119, c: 3.5450\n",
      "Epoch [400/10000], Combined Loss: -33.7975, Objective Loss: -33.8003, Constraint Loss: 0.0028, Penalty: 0.0000, a: 3.0401, b: 3.4177, c: 3.5439\n",
      "Epoch [500/10000], Combined Loss: -33.8164, Objective Loss: -33.8192, Constraint Loss: 0.0028, Penalty: 0.0000, a: 3.0346, b: 3.4244, c: 3.5427\n",
      "Epoch [600/10000], Combined Loss: -33.8378, Objective Loss: -33.8406, Constraint Loss: 0.0028, Penalty: 0.0000, a: 3.0284, b: 3.4320, c: 3.5413\n",
      "Epoch [700/10000], Combined Loss: -33.8618, Objective Loss: -33.8646, Constraint Loss: 0.0028, Penalty: 0.0000, a: 3.0214, b: 3.4405, c: 3.5397\n",
      "Epoch [800/10000], Combined Loss: -33.8883, Objective Loss: -33.8911, Constraint Loss: 0.0028, Penalty: 0.0000, a: 3.0138, b: 3.4499, c: 3.5380\n",
      "Epoch [900/10000], Combined Loss: -33.9173, Objective Loss: -33.9201, Constraint Loss: 0.0028, Penalty: 0.0000, a: 3.0054, b: 3.4602, c: 3.5361\n",
      "Epoch [1000/10000], Combined Loss: -33.9488, Objective Loss: -33.9517, Constraint Loss: 0.0028, Penalty: 0.0000, a: 2.9962, b: 3.4714, c: 3.5340\n",
      "Epoch [1100/10000], Combined Loss: -33.9830, Objective Loss: -33.9858, Constraint Loss: 0.0028, Penalty: 0.0000, a: 2.9863, b: 3.4836, c: 3.5318\n",
      "Epoch [1200/10000], Combined Loss: -34.0199, Objective Loss: -34.0227, Constraint Loss: 0.0028, Penalty: 0.0000, a: 2.9757, b: 3.4967, c: 3.5294\n",
      "Epoch [1300/10000], Combined Loss: -34.0595, Objective Loss: -34.0623, Constraint Loss: 0.0028, Penalty: 0.0000, a: 2.9642, b: 3.5107, c: 3.5268\n",
      "Epoch [1400/10000], Combined Loss: -34.1019, Objective Loss: -34.1048, Constraint Loss: 0.0028, Penalty: 0.0000, a: 2.9519, b: 3.5258, c: 3.5240\n",
      "Epoch [1500/10000], Combined Loss: -34.1473, Objective Loss: -34.1502, Constraint Loss: 0.0028, Penalty: 0.0000, a: 2.9387, b: 3.5419, c: 3.5211\n",
      "Epoch [1600/10000], Combined Loss: -34.1958, Objective Loss: -34.1986, Constraint Loss: 0.0029, Penalty: 0.0000, a: 2.9247, b: 3.5591, c: 3.5179\n",
      "Epoch [1700/10000], Combined Loss: -34.2474, Objective Loss: -34.2502, Constraint Loss: 0.0029, Penalty: 0.0000, a: 2.9097, b: 3.5774, c: 3.5145\n",
      "Epoch [1800/10000], Combined Loss: -34.3023, Objective Loss: -34.3051, Constraint Loss: 0.0029, Penalty: 0.0000, a: 2.8938, b: 3.5969, c: 3.5110\n",
      "Epoch [1900/10000], Combined Loss: -34.3606, Objective Loss: -34.3635, Constraint Loss: 0.0029, Penalty: 0.0000, a: 2.8769, b: 3.6176, c: 3.5072\n",
      "Epoch [2000/10000], Combined Loss: -34.4226, Objective Loss: -34.4254, Constraint Loss: 0.0029, Penalty: 0.0000, a: 2.8589, b: 3.6396, c: 3.5032\n",
      "Epoch [2100/10000], Combined Loss: -34.4883, Objective Loss: -34.4911, Constraint Loss: 0.0029, Penalty: 0.0000, a: 2.8398, b: 3.6629, c: 3.4989\n",
      "Epoch [2200/10000], Combined Loss: -34.5579, Objective Loss: -34.5608, Constraint Loss: 0.0029, Penalty: 0.0000, a: 2.8196, b: 3.6877, c: 3.4944\n",
      "Epoch [2300/10000], Combined Loss: -34.6317, Objective Loss: -34.6346, Constraint Loss: 0.0029, Penalty: 0.0000, a: 2.7982, b: 3.7139, c: 3.4896\n",
      "Epoch [2400/10000], Combined Loss: -34.7098, Objective Loss: -34.7128, Constraint Loss: 0.0029, Penalty: 0.0000, a: 2.7755, b: 3.7416, c: 3.4846\n",
      "Epoch [2500/10000], Combined Loss: -34.7926, Objective Loss: -34.7955, Constraint Loss: 0.0029, Penalty: 0.0000, a: 2.7515, b: 3.7709, c: 3.4793\n",
      "Epoch [2600/10000], Combined Loss: -34.8801, Objective Loss: -34.8830, Constraint Loss: 0.0029, Penalty: 0.0000, a: 2.7261, b: 3.8020, c: 3.4737\n",
      "Epoch [2700/10000], Combined Loss: -34.9727, Objective Loss: -34.9757, Constraint Loss: 0.0029, Penalty: 0.0000, a: 2.6992, b: 3.8348, c: 3.4677\n",
      "Epoch [2800/10000], Combined Loss: -35.0707, Objective Loss: -35.0737, Constraint Loss: 0.0030, Penalty: 0.0000, a: 2.6707, b: 3.8696, c: 3.4615\n",
      "Epoch [2900/10000], Combined Loss: -35.1744, Objective Loss: -35.1773, Constraint Loss: 0.0030, Penalty: 0.0000, a: 2.6405, b: 3.9063, c: 3.4549\n",
      "Epoch [3000/10000], Combined Loss: -35.2840, Objective Loss: -35.2870, Constraint Loss: 0.0030, Penalty: 0.0000, a: 2.6086, b: 3.9452, c: 3.4479\n",
      "Epoch [3100/10000], Combined Loss: -35.4001, Objective Loss: -35.4031, Constraint Loss: 0.0030, Penalty: 0.0000, a: 2.5749, b: 3.9864, c: 3.4405\n",
      "Epoch [3200/10000], Combined Loss: -35.5229, Objective Loss: -35.5259, Constraint Loss: 0.0030, Penalty: 0.0000, a: 2.5391, b: 4.0299, c: 3.4327\n",
      "Epoch [3300/10000], Combined Loss: -35.6529, Objective Loss: -35.6560, Constraint Loss: 0.0030, Penalty: 0.0000, a: 2.5012, b: 4.0760, c: 3.4245\n",
      "Epoch [3400/10000], Combined Loss: -35.7906, Objective Loss: -35.7937, Constraint Loss: 0.0030, Penalty: 0.0000, a: 2.4611, b: 4.1248, c: 3.4158\n",
      "Epoch [3500/10000], Combined Loss: -35.9366, Objective Loss: -35.9396, Constraint Loss: 0.0031, Penalty: 0.0000, a: 2.4186, b: 4.1765, c: 3.4067\n",
      "Epoch [3600/10000], Combined Loss: -36.0913, Objective Loss: -36.0943, Constraint Loss: 0.0031, Penalty: 0.0000, a: 2.3735, b: 4.2313, c: 3.3970\n",
      "Epoch [3700/10000], Combined Loss: -36.2554, Objective Loss: -36.2585, Constraint Loss: 0.0031, Penalty: 0.0000, a: 2.3256, b: 4.2894, c: 3.3868\n",
      "Epoch [3800/10000], Combined Loss: -36.4297, Objective Loss: -36.4328, Constraint Loss: 0.0031, Penalty: 0.0000, a: 2.2747, b: 4.3511, c: 3.3759\n",
      "Epoch [3900/10000], Combined Loss: -36.6149, Objective Loss: -36.6180, Constraint Loss: 0.0031, Penalty: 0.0000, a: 2.2206, b: 4.4167, c: 3.3644\n",
      "Epoch [4000/10000], Combined Loss: -36.8119, Objective Loss: -36.8151, Constraint Loss: 0.0032, Penalty: 0.0000, a: 2.1631, b: 4.4864, c: 3.3523\n",
      "Epoch [4100/10000], Combined Loss: -37.0218, Objective Loss: -37.0250, Constraint Loss: 0.0032, Penalty: 0.0000, a: 2.1017, b: 4.5607, c: 3.3394\n",
      "Epoch [4200/10000], Combined Loss: -37.2457, Objective Loss: -37.2489, Constraint Loss: 0.0032, Penalty: 0.0000, a: 2.0362, b: 4.6399, c: 3.3257\n",
      "Epoch [4300/10000], Combined Loss: -37.4849, Objective Loss: -37.4881, Constraint Loss: 0.0032, Penalty: 0.0000, a: 1.9662, b: 4.7245, c: 3.3111\n",
      "Epoch [4400/10000], Combined Loss: -37.7409, Objective Loss: -37.7442, Constraint Loss: 0.0033, Penalty: 0.0000, a: 1.8912, b: 4.8150, c: 3.2956\n",
      "Epoch [4500/10000], Combined Loss: -38.0154, Objective Loss: -38.0187, Constraint Loss: 0.0033, Penalty: 0.0000, a: 1.8108, b: 4.9120, c: 3.2790\n",
      "Epoch [4600/10000], Combined Loss: -38.3105, Objective Loss: -38.3139, Constraint Loss: 0.0033, Penalty: 0.0000, a: 1.7242, b: 5.0163, c: 3.2613\n",
      "Epoch [4700/10000], Combined Loss: -38.6286, Objective Loss: -38.6320, Constraint Loss: 0.0034, Penalty: 0.0000, a: 1.6309, b: 5.1287, c: 3.2423\n",
      "Epoch [4800/10000], Combined Loss: -38.9724, Objective Loss: -38.9758, Constraint Loss: 0.0034, Penalty: 0.0000, a: 1.5299, b: 5.2501, c: 3.2218\n",
      "Epoch [4900/10000], Combined Loss: -39.3453, Objective Loss: -39.3487, Constraint Loss: 0.0034, Penalty: 0.0000, a: 1.4203, b: 5.3818, c: 3.1998\n",
      "Epoch [5000/10000], Combined Loss: -39.7514, Objective Loss: -39.7548, Constraint Loss: 0.0035, Penalty: 0.0000, a: 1.3009, b: 5.5251, c: 3.1759\n",
      "Epoch [5100/10000], Combined Loss: -40.1955, Objective Loss: -40.1990, Constraint Loss: 0.0035, Penalty: 0.0000, a: 1.1702, b: 5.6818, c: 3.1499\n",
      "Epoch [5200/10000], Combined Loss: -40.6837, Objective Loss: -40.6873, Constraint Loss: 0.0036, Penalty: 0.0000, a: 1.0264, b: 5.8540, c: 3.1216\n",
      "Epoch [5300/10000], Combined Loss: -41.2236, Objective Loss: -41.2272, Constraint Loss: 0.0036, Penalty: 0.0000, a: 0.8672, b: 6.0443, c: 3.0904\n",
      "Epoch [5400/10000], Combined Loss: -41.8246, Objective Loss: -41.8282, Constraint Loss: 0.0037, Penalty: 0.0000, a: 0.6899, b: 6.2562, c: 3.0558\n",
      "Epoch [5500/10000], Combined Loss: -42.4989, Objective Loss: -42.5026, Constraint Loss: 0.0037, Penalty: 0.0000, a: 0.4908, b: 6.4938, c: 3.0173\n",
      "Epoch [5600/10000], Combined Loss: -43.2201, Objective Loss: -43.2374, Constraint Loss: 0.0173, Penalty: 0.0000, a: 0.2658, b: 6.7578, c: 2.9722\n",
      "Epoch [5700/10000], Combined Loss: -44.1202, Objective Loss: -44.1241, Constraint Loss: 0.0039, Penalty: 0.0000, a: 0.0117, b: 7.0649, c: 2.9254\n",
      "Epoch [5800/10000], Combined Loss: -42.6074, Objective Loss: -42.6115, Constraint Loss: 0.0041, Penalty: 0.0000, a: 0.7919, b: 6.6987, c: 2.5115\n",
      "Epoch [5900/10000], Combined Loss: -43.3714, Objective Loss: -43.3752, Constraint Loss: 0.0039, Penalty: 0.0000, a: 0.5841, b: 6.9767, c: 2.4412\n",
      "Epoch [6000/10000], Combined Loss: -44.2460, Objective Loss: -44.2499, Constraint Loss: 0.0040, Penalty: 0.0000, a: 0.3464, b: 7.2952, c: 2.3603\n",
      "Epoch [6100/10000], Combined Loss: -45.2605, Objective Loss: -45.2645, Constraint Loss: 0.0040, Penalty: 0.0000, a: 0.0711, b: 7.6648, c: 2.2661\n",
      "Epoch [6200/10000], Combined Loss: -43.6871, Objective Loss: -43.7038, Constraint Loss: 0.0167, Penalty: 0.0000, a: 0.8838, b: 7.2877, c: 1.8326\n",
      "Epoch [6300/10000], Combined Loss: -44.5955, Objective Loss: -44.5996, Constraint Loss: 0.0041, Penalty: 0.0000, a: 0.6599, b: 7.6267, c: 1.7154\n",
      "Epoch [6400/10000], Combined Loss: -45.6492, Objective Loss: -45.6533, Constraint Loss: 0.0042, Penalty: 0.0000, a: 0.4002, b: 8.0237, c: 1.5781\n",
      "Epoch [6500/10000], Combined Loss: -46.8971, Objective Loss: -46.9013, Constraint Loss: 0.0042, Penalty: 0.0000, a: 0.0938, b: 8.4945, c: 1.4138\n",
      "Epoch [6600/10000], Combined Loss: -45.2333, Objective Loss: -45.2333, Constraint Loss: 0.0000, Penalty: 0.0000, a: 0.9590, b: 8.0964, c: 0.9445\n",
      "Epoch [6700/10000], Combined Loss: -46.3586, Objective Loss: -46.3629, Constraint Loss: 0.0043, Penalty: 0.0000, a: 0.7112, b: 8.5339, c: 0.7570\n",
      "Epoch [6800/10000], Combined Loss: -47.6973, Objective Loss: -47.7016, Constraint Loss: 0.0043, Penalty: 0.0000, a: 0.4165, b: 9.0559, c: 0.5297\n",
      "Epoch [6900/10000], Combined Loss: -49.3307, Objective Loss: -49.3351, Constraint Loss: 0.0044, Penalty: 0.0000, a: 0.0593, b: 9.6941, c: 0.2487\n",
      "Epoch [7000/10000], Combined Loss: -45.5846, Objective Loss: -45.5872, Constraint Loss: 0.0026, Penalty: 0.0000, a: 0.8016, b: 8.1968, c: 0.9999\n",
      "Epoch [7100/10000], Combined Loss: -46.5351, Objective Loss: -46.5395, Constraint Loss: 0.0044, Penalty: 0.0000, a: 0.5737, b: 8.5535, c: 0.8750\n",
      "Epoch [7200/10000], Combined Loss: -47.6304, Objective Loss: -47.6350, Constraint Loss: 0.0045, Penalty: 0.0000, a: 0.3078, b: 8.9682, c: 0.7261\n",
      "Epoch [7300/10000], Combined Loss: -35.8340, Objective Loss: -49.1189, Constraint Loss: 13.2849, Penalty: 0.0000, a: 0.1220, b: 9.4476, c: 0.5457\n",
      "Epoch [7400/10000], Combined Loss: -47.1579, Objective Loss: -47.1606, Constraint Loss: 0.0027, Penalty: 0.0000, a: 0.8279, b: 8.9918, c: 0.1820\n",
      "Epoch [7500/10000], Combined Loss: -46.3131, Objective Loss: -47.0737, Constraint Loss: 0.7606, Penalty: 0.0000, a: 0.4376, b: 8.7970, c: 0.7379\n",
      "Epoch [7600/10000], Combined Loss: -47.6796, Objective Loss: -47.6827, Constraint Loss: 0.0031, Penalty: 0.0000, a: 0.1187, b: 8.8981, c: 0.9850\n",
      "Epoch [7700/10000], Combined Loss: -46.0974, Objective Loss: -46.1041, Constraint Loss: 0.0067, Penalty: 0.0000, a: 0.8477, b: 8.4798, c: 0.6699\n",
      "Epoch [7800/10000], Combined Loss: -47.1173, Objective Loss: -47.1221, Constraint Loss: 0.0047, Penalty: 0.0000, a: 0.6153, b: 8.8654, c: 0.5214\n",
      "Epoch [7900/10000], Combined Loss: -48.2972, Objective Loss: -48.3019, Constraint Loss: 0.0047, Penalty: 0.0000, a: 0.3403, b: 9.3178, c: 0.3440\n",
      "Epoch [8000/10000], Combined Loss: -49.7122, Objective Loss: -49.7170, Constraint Loss: 0.0048, Penalty: 0.0000, a: 0.0122, b: 9.8613, c: 0.1286\n",
      "Epoch [8100/10000], Combined Loss: -46.1444, Objective Loss: -46.1480, Constraint Loss: 0.0036, Penalty: 0.0000, a: 0.7110, b: 8.4267, c: 0.8642\n",
      "Epoch [8200/10000], Combined Loss: -47.1129, Objective Loss: -47.1177, Constraint Loss: 0.0048, Penalty: 0.0000, a: 0.4750, b: 8.7931, c: 0.7341\n",
      "Epoch [8300/10000], Combined Loss: -48.2487, Objective Loss: -48.2535, Constraint Loss: 0.0048, Penalty: 0.0000, a: 0.1995, b: 9.2232, c: 0.5795\n",
      "Epoch [8400/10000], Combined Loss: -46.5834, Objective Loss: -46.6749, Constraint Loss: 0.0915, Penalty: 0.0000, a: 0.9183, b: 8.8110, c: 0.2612\n",
      "Epoch [8500/10000], Combined Loss: -47.7455, Objective Loss: -47.7499, Constraint Loss: 0.0045, Penalty: 0.0000, a: 0.6991, b: 9.2213, c: 0.0817\n",
      "Epoch [8600/10000], Combined Loss: -47.1362, Objective Loss: -47.1409, Constraint Loss: 0.0047, Penalty: 0.0000, a: 0.2966, b: 8.7220, c: 0.9793\n",
      "Epoch [8700/10000], Combined Loss: -48.2677, Objective Loss: -48.2725, Constraint Loss: 0.0048, Penalty: 0.0000, a: 0.0176, b: 9.1418, c: 0.8428\n",
      "Epoch [8800/10000], Combined Loss: -46.6351, Objective Loss: -46.6409, Constraint Loss: 0.0057, Penalty: 0.0000, a: 0.7531, b: 8.6934, c: 0.5560\n",
      "Epoch [8900/10000], Combined Loss: -47.7003, Objective Loss: -47.7052, Constraint Loss: 0.0049, Penalty: 0.0000, a: 0.5049, b: 9.1017, c: 0.3956\n",
      "Epoch [9000/10000], Combined Loss: -48.9636, Objective Loss: -48.9685, Constraint Loss: 0.0049, Penalty: 0.0000, a: 0.2122, b: 9.5870, c: 0.2030\n",
      "Epoch [9100/10000], Combined Loss: -45.7178, Objective Loss: -45.7401, Constraint Loss: 0.0224, Penalty: 0.0000, a: 0.8130, b: 8.2695, c: 0.9222\n",
      "Epoch [9200/10000], Combined Loss: -46.5446, Objective Loss: -46.5493, Constraint Loss: 0.0047, Penalty: 0.0000, a: 0.6046, b: 8.5737, c: 0.8239\n",
      "Epoch [9300/10000], Combined Loss: -47.6232, Objective Loss: -47.6281, Constraint Loss: 0.0050, Penalty: 0.0000, a: 0.3465, b: 8.9840, c: 0.6717\n",
      "Epoch [9400/10000], Combined Loss: -48.9064, Objective Loss: -48.9115, Constraint Loss: 0.0051, Penalty: 0.0000, a: 0.0410, b: 9.4729, c: 0.4884\n",
      "Epoch [9500/10000], Combined Loss: -47.1897, Objective Loss: -47.1911, Constraint Loss: 0.0014, Penalty: 0.0000, a: 0.8182, b: 9.0029, c: 0.1801\n",
      "Epoch [9600/10000], Combined Loss: -43.3267, Objective Loss: -47.4142, Constraint Loss: 4.0875, Penalty: 0.0000, a: 0.4741, b: 8.8483, c: 0.7415\n",
      "Epoch [9700/10000], Combined Loss: -47.6546, Objective Loss: -47.6601, Constraint Loss: 0.0056, Penalty: 0.0000, a: 0.1731, b: 8.9131, c: 0.9161\n",
      "Epoch [9800/10000], Combined Loss: -46.1583, Objective Loss: -46.2318, Constraint Loss: 0.0736, Penalty: 0.0000, a: 0.8451, b: 8.5256, c: 0.6379\n",
      "Epoch [9900/10000], Combined Loss: -47.1483, Objective Loss: -47.1536, Constraint Loss: 0.0052, Penalty: 0.0000, a: 0.6303, b: 8.8885, c: 0.4835\n",
      "Epoch [10000/10000], Combined Loss: -48.3067, Objective Loss: -48.3117, Constraint Loss: 0.0050, Penalty: 0.0000, a: 0.3646, b: 9.3348, c: 0.3028\n",
      "Optimized values - a: 0.3617, b: 9.3397, c: 0.3008\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the encoder-decoder model\n",
    "class EncoderDecoderModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, latent_size):\n",
    "        super(EncoderDecoderModel, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, latent_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 3)  # Output 3 values for a, b, and c\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        outputs = self.decoder(latent)\n",
    "        a, b, c = outputs[:, 0], outputs[:, 1], outputs[:, 2]\n",
    "        return a, b, c\n",
    "\n",
    "# Objective function\n",
    "def loss1(a, b, c):\n",
    "    return -(a * 2 + b * 5 + c * 3).mean()\n",
    "\n",
    "def loss2(a, b, c):\n",
    "    return ((a + b + c - 10) ** 2).mean() * 1000.\n",
    "\n",
    "def loss3(a, b, c):\n",
    "    penalty = torch.relu(-a) + torch.relu(-b) + torch.relu(-c)\n",
    "    return penalty.mean() * 1000.  # Large penalty to enforce non-negativity\n",
    "\n",
    "# Initialize the model\n",
    "input_size = 1  # Dummy input size, since we're directly optimizing a, b, and c\n",
    "hidden_size = 10\n",
    "latent_size = 5\n",
    "model = EncoderDecoderModel(input_size, hidden_size, latent_size)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10000\n",
    "batch_size = 100\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Dummy input for the batch (all ones to simulate intercept learning)\n",
    "    x_dummy = torch.ones(batch_size, input_size)\n",
    "    \n",
    "    # Forward pass\n",
    "    a, b, c = model(x_dummy)\n",
    "    \n",
    "    # Compute losses\n",
    "    obj_loss = loss1(a, b, c)\n",
    "    const_loss = loss2(a, b, c)\n",
    "    non_neg_penalty = loss3(a, b, c)\n",
    "    \n",
    "    # Combine losses with weights\n",
    "    combined_loss = obj_loss + const_loss + non_neg_penalty\n",
    "    combined_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Combined Loss: {combined_loss.item():.4f}, Objective Loss: {obj_loss.item():.4f}, Constraint Loss: {const_loss.item():.4f}, Penalty: {non_neg_penalty.item():.4f}, a: {a.mean().item():.4f}, b: {b.mean().item():.4f}, c: {c.mean().item():.4f}')\n",
    "\n",
    "# Final optimized values (using a single input to get final values)\n",
    "x_dummy = torch.ones(1, input_size)  # Single input to get final values\n",
    "a_opt, b_opt, c_opt = model(x_dummy)\n",
    "print(f'Optimized values - a: {a_opt.item():.4f}, b: {b_opt.item():.4f}, c: {c_opt.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b175b780",
   "metadata": {},
   "source": [
    "### Regression Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "66bf79e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.1263\n",
      "Epoch [200/1000], Loss: 0.0249\n",
      "Epoch [300/1000], Loss: 0.0082\n",
      "Epoch [400/1000], Loss: 0.0032\n",
      "Epoch [500/1000], Loss: 0.0049\n",
      "Epoch [600/1000], Loss: 0.0018\n",
      "Epoch [700/1000], Loss: 0.0046\n",
      "Epoch [800/1000], Loss: 0.0015\n",
      "Epoch [900/1000], Loss: 0.0015\n",
      "Epoch [1000/1000], Loss: 0.0019\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value: 3.0144801139831543 at X: 2.929292917251587\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate data for the optimization problem\n",
    "X = np.linspace(0, 5, 100).reshape(-1, 1)  # Features\n",
    "y = -X**2 + 4*X  # Labels (objective function values)\n",
    "y = np.where(y > 3, 3, y)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Define a simple neural network\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.output = nn.Linear(hidden_size, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "input_size = 1\n",
    "hidden_size = 10\n",
    "model = NeuralNetwork(input_size, hidden_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_tensor)\n",
    "    loss = criterion(outputs, y_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predicted = model(X_tensor).numpy()\n",
    "\n",
    "# Plot the results\n",
    "plt.scatter(X, y, label='Original Data')\n",
    "plt.plot(X, predicted, label='Fitted Line', color='red')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('f(X)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Find the optimal solution\n",
    "X_new = torch.tensor(np.linspace(0, 5, 100).reshape(-1, 1), dtype=torch.float32)\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_new)\n",
    "optimal_value, optimal_index = torch.max(predictions, 0)\n",
    "optimal_x = X_new[optimal_index]\n",
    "\n",
    "print(f'Optimal value: {optimal_value.item()} at X: {optimal_x.item()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ec5f2b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fb505c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.0720\n",
      "Epoch [2/10], Loss: 0.0643\n",
      "Epoch [3/10], Loss: 0.0620\n",
      "Epoch [4/10], Loss: 0.0593\n",
      "Epoch [5/10], Loss: 0.0604\n",
      "Epoch [6/10], Loss: 0.0588\n",
      "Epoch [7/10], Loss: 0.0586\n",
      "Epoch [8/10], Loss: 0.0592\n",
      "Epoch [9/10], Loss: 0.0587\n",
      "Epoch [10/10], Loss: 0.0577\n",
      "Mean Squared Error (MSE): 0.0571\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.features = torch.tensor(X, dtype=torch.float32)\n",
    "        self.targets = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.output = nn.Linear(hidden_size, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.output(x)  # No sigmoid here\n",
    "        return x\n",
    "\n",
    "\n",
    "data = {\n",
    "    'feature1': [1.0, 2.0, 3.0, 4.0],\n",
    "    'feature2': [5.0, 6.0, 7.0, 8.0],\n",
    "    'feature3': [9.0, 10.0, 11.0, 12.0],\n",
    "    'target': [0.0, 0.2, 0.4, 0.6]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split into features and targets\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Create dataset and dataloader\n",
    "batch_size = 2\n",
    "dataset = CustomDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Instantiate the model, define the loss function and the optimizer\n",
    "input_size = X.shape[1]\n",
    "hidden_size = 5\n",
    "model = NeuralNetwork(input_size, hidden_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for batch_features, batch_targets in dataloader:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_features)\n",
    "        scaled_outputs = torch.sigmoid(outputs)  # Scale the output to [0, 1] here\n",
    "        loss = criterion(scaled_outputs, batch_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_epoch_loss = epoch_loss / len(dataloader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_epoch_loss:.4f}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "val_dataset = CustomDataset(X, y)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False)\n",
    "\n",
    "predicted_values = []\n",
    "target_values = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_features, batch_targets in val_dataloader:\n",
    "        outputs = model(batch_features)\n",
    "        scaled_outputs = torch.sigmoid(outputs)  # Scale the output to [0, 1] here\n",
    "        predicted_values.extend(scaled_outputs.numpy())\n",
    "        target_values.extend(batch_targets.numpy())\n",
    "\n",
    "# Compute MSE\n",
    "predicted_values = torch.tensor(predicted_values).view(-1)\n",
    "target_values = torch.tensor(target_values).view(-1)\n",
    "\n",
    "mse = mean_squared_error(target_values, predicted_values)\n",
    "print(f'Mean Squared Error (MSE): {mse:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
