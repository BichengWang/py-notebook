{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simplified two-tower embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 18:36:10.166251: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-05-28 18:36:10.166377: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 18:36:10.702792: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-05-28 18:36:10.897086: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 10ms/step - loss: 17.6313\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 17.6264\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 17.6225\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 17.6186\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 17.6141\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 17.6093\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 17.6049\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 17.6003\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 17.5957\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 17.5898\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " user_input (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " item_input (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1, 8)         40          ['user_input[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 1, 8)         40          ['item_input[0][0]']             \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 8)            0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 8)            0           ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 8)            0           ['flatten[0][0]',                \n",
      "                                                                  'flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum (TFOpLambda  (None,)             0           ['tf.math.multiply[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 80\n",
      "Trainable params: 80\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Example data\n",
    "users = pd.DataFrame({\n",
    "    'user_id': [1, 2, 3, 4],\n",
    "    'user_age': [25, 34, 28, 22],\n",
    "    'user_gender': ['M', 'F', 'M', 'F']\n",
    "})\n",
    "\n",
    "items = pd.DataFrame({\n",
    "    'item_id': [1, 2, 3, 4],\n",
    "    'movie_title': ['The Matrix', 'Titanic', 'The Godfather', 'The Shawshank Redemption'],\n",
    "    'movie_genre': ['Sci-Fi', 'Romance', 'Crime', 'Drama']\n",
    "})\n",
    "\n",
    "ratings = pd.DataFrame({\n",
    "    'user_id': [1, 1, 2, 2, 3, 3, 4, 4],\n",
    "    'item_id': [1, 2, 2, 3, 1, 4, 2, 4],\n",
    "    'rating': [5, 3, 4, 5, 4, 5, 3, 4]\n",
    "})\n",
    "\n",
    "# Encode categorical features\n",
    "user_gender_encoder = LabelEncoder()\n",
    "users['user_gender'] = user_gender_encoder.fit_transform(users['user_gender'])\n",
    "\n",
    "# Normalize numerical features\n",
    "age_scaler = MinMaxScaler()\n",
    "users['user_age'] = age_scaler.fit_transform(users[['user_age']])\n",
    "\n",
    "# Encode movie genre\n",
    "movie_genre_encoder = LabelEncoder()\n",
    "items['movie_genre'] = movie_genre_encoder.fit_transform(items['movie_genre'])\n",
    "\n",
    "# Prepare input data\n",
    "user_input = ratings['user_id'].values\n",
    "item_input = ratings['item_id'].values\n",
    "ratings_input = ratings['rating'].values\n",
    "\n",
    "# Example model architecture\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# User tower\n",
    "user_input_layer = Input(shape=(1,), name='user_input')\n",
    "user_embedding = Embedding(input_dim=len(users)+1, output_dim=8)(user_input_layer)\n",
    "user_vec = Flatten()(user_embedding)\n",
    "\n",
    "# Item tower\n",
    "item_input_layer = Input(shape=(1,), name='item_input')\n",
    "item_embedding = Embedding(input_dim=len(items)+1, output_dim=8)(item_input_layer)\n",
    "item_vec = Flatten()(item_embedding)\n",
    "\n",
    "# Dot product to calculate similarity\n",
    "dot_product = tf.reduce_sum(tf.multiply(user_vec, item_vec), axis=1)\n",
    "\n",
    "# Final model\n",
    "model = Model(inputs=[user_input_layer, item_input_layer], outputs=dot_product)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit([user_input, item_input], ratings_input, epochs=10, batch_size=2)\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   4/1250 [..............................] - ETA: 23s - loss: 13.9053 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 18:58:40.736097: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 5s 4ms/step - loss: 12.0647\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 3.7053\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.5645\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.1455\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.9979\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 4s 4ms/step - loss: 0.9342\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.9033\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 4s 4ms/step - loss: 0.8857\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 4s 4ms/step - loss: 0.8748\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.8663\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " user_input (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " item_input (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " user_embedding (Embedding)     (None, 1, 8)         7552        ['user_input[0][0]']             \n",
      "                                                                                                  \n",
      " item_embedding (Embedding)     (None, 1, 8)         13464       ['item_input[0][0]']             \n",
      "                                                                                                  \n",
      " user_flatten (Flatten)         (None, 8)            0           ['user_embedding[0][0]']         \n",
      "                                                                                                  \n",
      " item_flatten (Flatten)         (None, 8)            0           ['item_embedding[0][0]']         \n",
      "                                                                                                  \n",
      " dot_product (Dot)              (None, 1)            0           ['user_flatten[0][0]',           \n",
      "                                                                  'item_flatten[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,016\n",
      "Trainable params: 21,016\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "130/625 [=====>........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 18:59:26.398761: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 1s 1ms/step\n",
      "Mean Squared Error (MSE): 0.9120335695677148\n",
      "Root Mean Squared Error (RMSE): 0.955004486674128\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Dot\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import zipfile\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "# Example data\n",
    "# ratings = pd.DataFrame({\n",
    "#     'user_id': [1, 1, 2, 2, 3, 3, 4, 4],\n",
    "#     'item_id': [1, 2, 2, 3, 1, 4, 2, 4],\n",
    "#     'rating': [5, 3, 4, 5, 4, 5, 3, 4]\n",
    "# })\n",
    "\n",
    "# # Prepare input data\n",
    "# user_input = ratings['user_id'].values\n",
    "# item_input = ratings['item_id'].values\n",
    "# ratings_input = ratings['rating'].values\n",
    "\n",
    "# # Model parameters\n",
    "# num_users = ratings['user_id'].nunique()\n",
    "# num_items = ratings['item_id'].nunique()\n",
    "\n",
    "\n",
    "# Download and extract the dataset\n",
    "url = 'http://files.grouplens.org/datasets/movielens/ml-100k.zip'\n",
    "urllib.request.urlretrieve(url, '../../../data/.local/ml-100k.zip')\n",
    "with zipfile.ZipFile('../../../data/.local/ml-100k.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('.')\n",
    "\n",
    "# Load data into pandas DataFrame\n",
    "ratings = pd.read_csv('../../../data/.local/ml-100k/u.data', sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "ratings.drop(columns=['timestamp'], inplace=True)\n",
    "\n",
    "# Prepare input data\n",
    "user_input = ratings['user_id'].values\n",
    "item_input = ratings['item_id'].values\n",
    "ratings_input = ratings['rating'].values\n",
    "\n",
    "# Split data into training and testing sets\n",
    "user_train, user_test, item_train, item_test, ratings_train, ratings_test = train_test_split(\n",
    "    user_input, item_input, ratings_input, test_size=0.2, random_state=42)\n",
    "\n",
    "num_users = ratings['user_id'].nunique()\n",
    "num_items = ratings['item_id'].nunique()\n",
    "\n",
    "embedding_dim = 8\n",
    "\n",
    "# User tower\n",
    "user_input_layer = Input(shape=(1,), name='user_input')\n",
    "user_embedding = Embedding(input_dim=num_users+1, output_dim=embedding_dim, name='user_embedding')(user_input_layer)\n",
    "user_vec = Flatten(name='user_flatten')(user_embedding)\n",
    "\n",
    "# Item tower\n",
    "item_input_layer = Input(shape=(1,), name='item_input')\n",
    "item_embedding = Embedding(input_dim=num_items+1, output_dim=embedding_dim, name='item_embedding')(item_input_layer)\n",
    "item_vec = Flatten(name='item_flatten')(item_embedding)\n",
    "\n",
    "# Dot product to calculate similarity\n",
    "dot_product = Dot(axes=1, name='dot_product')([user_vec, item_vec])\n",
    "\n",
    "# Final model\n",
    "model = Model(inputs=[user_input_layer, item_input_layer], outputs=dot_product)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit([user_train, item_train], ratings_train, epochs=10, batch_size=64, verbose=1)\n",
    "\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict([user_test, item_test])\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(ratings_test, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simplified graph embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   5/1250 [..............................] - ETA: 16s - loss: 13.5537 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 18:43:18.351864: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 5s 3ms/step - loss: 11.9528\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 3.5396\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5267\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.1334\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 4s 4ms/step - loss: 0.9943\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.9358\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.9068\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.8913\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.8819\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.8755\n",
      "142/625 [=====>........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 18:44:02.913787: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 1s 1ms/step\n",
      "Mean Squared Error (MSE): 0.9169867498032821\n",
      "Root Mean Squared Error (RMSE): 0.9575942511331624\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Dot\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import zipfile\n",
    "import urllib.request\n",
    "\n",
    "# Download and extract the dataset\n",
    "url = 'http://files.grouplens.org/datasets/movielens/ml-100k.zip'\n",
    "urllib.request.urlretrieve(url, '../../../data/.local/ml-100k.zip')\n",
    "with zipfile.ZipFile('../../../data/.local/ml-100k.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('.')\n",
    "\n",
    "# Load data into pandas DataFrame\n",
    "ratings = pd.read_csv('../../../data/.local/ml-100k/u.data', sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "ratings.drop(columns=['timestamp'], inplace=True)\n",
    "\n",
    "# Prepare input data\n",
    "user_input = ratings['user_id'].values\n",
    "item_input = ratings['item_id'].values\n",
    "ratings_input = ratings['rating'].values\n",
    "\n",
    "# Split data into training and testing sets\n",
    "user_train, user_test, item_train, item_test, ratings_train, ratings_test = train_test_split(\n",
    "    user_input, item_input, ratings_input, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model parameters\n",
    "num_users = ratings['user_id'].nunique()\n",
    "num_items = ratings['item_id'].nunique()\n",
    "embedding_dim = 8\n",
    "\n",
    "# User tower\n",
    "user_input_layer = Input(shape=(1,), name='user_input')\n",
    "user_embedding = Embedding(input_dim=num_users+1, output_dim=embedding_dim, name='user_embedding')(user_input_layer)\n",
    "user_vec = Flatten(name='user_flatten')(user_embedding)\n",
    "\n",
    "# Item tower\n",
    "item_input_layer = Input(shape=(1,), name='item_input')\n",
    "item_embedding = Embedding(input_dim=num_items+1, output_dim=embedding_dim, name='item_embedding')(item_input_layer)\n",
    "item_vec = Flatten(name='item_flatten')(item_embedding)\n",
    "\n",
    "# Dot product to calculate similarity\n",
    "dot_product = Dot(axes=1, name='dot_product')([user_vec, item_vec])\n",
    "\n",
    "# Final model\n",
    "model = Model(inputs=[user_input_layer, item_input_layer], outputs=dot_product)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit([user_train, item_train], ratings_train, epochs=10, batch_size=64, verbose=1)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict([user_test, item_test])\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(ratings_test, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './two_tower_embedding_model.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m plot_model(model, to_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./two_tower_embedding_model.png\u001b[39m\u001b[38;5;124m'\u001b[39m, show_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, show_layer_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Display the model plot\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./two_tower_embedding_model.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.8/site-packages/IPython/core/display.py:970\u001b[0m, in \u001b[0;36mImage.__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata, alt)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munconfined \u001b[38;5;241m=\u001b[39m unconfined\n\u001b[1;32m    969\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malt \u001b[38;5;241m=\u001b[39m alt\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m, {}):\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m=\u001b[39m metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.8/site-packages/IPython/core/display.py:327\u001b[0m, in \u001b[0;36mDisplayObject.__init__\u001b[0;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 327\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_data()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.8/site-packages/IPython/core/display.py:1005\u001b[0m, in \u001b[0;36mImage.reload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m-> 1005\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1006\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretina:\n\u001b[1;32m   1007\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retina_shape()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/python-notebook/lib/python3.8/site-packages/IPython/core/display.py:353\u001b[0m, in \u001b[0;36mDisplayObject.reload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_flags \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 353\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_flags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    354\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;66;03m# Deferred import\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './two_tower_embedding_model.png'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import Image\n",
    "\n",
    "# Plot the model\n",
    "plot_model(model, to_file='./two_tower_embedding_model.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# Display the model plot\n",
    "Image(filename='./two_tower_embedding_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
