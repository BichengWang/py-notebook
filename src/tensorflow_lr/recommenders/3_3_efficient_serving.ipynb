{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32b4b51f",
   "metadata": {},
   "source": [
    "# Efficient serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc0ecf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Text\n",
    "\n",
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aee9ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dd63e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MovieLens 100K data.\n",
    "ratings = tfds.load(\n",
    "    \"movielens/100k-ratings\",\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "# Get the ratings data.\n",
    "ratings = (ratings\n",
    "           # Retain only the fields we need.\n",
    "           .map(lambda x: {\"user_id\": x[\"user_id\"], \"movie_title\": x[\"movie_title\"]})\n",
    "           # Cache for efficiency.\n",
    "           .cache(tempfile.NamedTemporaryFile().name)\n",
    ")\n",
    "\n",
    "# Get the movies data.\n",
    "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")\n",
    "movies = (movies\n",
    "          # Retain only the fields we need.\n",
    "          .map(lambda x: x[\"movie_title\"])\n",
    "          # Cache for efficiency.\n",
    "          .cache(tempfile.NamedTemporaryFile().name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe64c445",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = ratings.map(lambda x: x[\"user_id\"])\n",
    "\n",
    "unique_movie_titles = np.unique(np.concatenate(list(movies.batch(1000))))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids.batch(1000))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4082b1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7ddfd0",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec00ccc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovielensModel(tfrs.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        embedding_dimension = 32\n",
    "        # Set up a model for representing movies.\n",
    "        self.movie_model = tf.keras.Sequential([\n",
    "          tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_movie_titles, mask_token=None),\n",
    "          # We add an additional embedding to account for unknown tokens.\n",
    "          tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "        ])\n",
    "        # Set up a model for representing users.\n",
    "        self.user_model = tf.keras.Sequential([\n",
    "          tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_user_ids, mask_token=None),\n",
    "            # We add an additional embedding to account for unknown tokens.\n",
    "          tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "        ])\n",
    "        # Set up a task to optimize the model and compute metrics.\n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "          metrics=tfrs.metrics.FactorizedTopK(\n",
    "            candidates=(\n",
    "                movies\n",
    "                .batch(128)\n",
    "                .cache()\n",
    "                .map(lambda title: (title, self.movie_model(title)))\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "        \n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        # We pick out the user features and pass them into the user model.\n",
    "        user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        # And pick out the movie features and pass them into the movie model,\n",
    "        # getting embeddings back.\n",
    "        positive_movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    "        # The task computes the loss and the metrics.\n",
    "        return self.task(\n",
    "            user_embeddings,\n",
    "            positive_movie_embeddings,\n",
    "            candidate_ids=features[\"movie_title\"],\n",
    "            compute_metrics=not training\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dda2a75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MovielensModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d3682f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10/10 [==============================] - 4s 30ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 69874.7145 - regularization_loss: 0.0000e+00 - total_loss: 69874.7145\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 2s 31ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 67507.4659 - regularization_loss: 0.0000e+00 - total_loss: 67507.4659\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 2s 29ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 66310.9773 - regularization_loss: 0.0000e+00 - total_loss: 66310.9773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f8526bcd00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train.batch(8192), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6266be96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 8s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0022 - factorized_top_k/top_5_categorical_accuracy: 0.0103 - factorized_top_k/top_10_categorical_accuracy: 0.0235 - factorized_top_k/top_50_categorical_accuracy: 0.1252 - factorized_top_k/top_100_categorical_accuracy: 0.2380 - loss: 49458.1230 - regularization_loss: 0.0000e+00 - total_loss: 49458.1230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.00215000007301569,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.010300000198185444,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.02345000021159649,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.12520000338554382,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.23800000548362732,\n",
       " 'loss': 28244.69921875,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 28244.69921875}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test.batch(8192), return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4e13f",
   "metadata": {},
   "source": [
    "### Approximate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04a27392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x1f8526d1ee0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brute_force = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "brute_force.index_from_dataset(\n",
    "    movies.batch(128).map(lambda title: (title, model.movie_model(title)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc12e210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommendations: [b\"Kid in King Arthur's Court, A (1995)\"\n",
      " b'Bedknobs and Broomsticks (1971)'\n",
      " b'Homeward Bound: The Incredible Journey (1993)']\n"
     ]
    }
   ],
   "source": [
    "# Get predictions for user 42.\n",
    "_, titles = brute_force(np.array([\"42\"]), k=3)\n",
    "\n",
    "print(f\"Top recommendations: {titles[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "201aa398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.84 ms ± 238 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _, titles = brute_force(np.array([\"42\"]), k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28df52ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a dataset of movies that's 1,000 times larger. We \n",
    "# do this by adding several million dummy movie titles to the dataset.\n",
    "lots_of_movies = tf.data.Dataset.concatenate(\n",
    "    movies.batch(4096),\n",
    "    movies.batch(4096).repeat(1_000).map(lambda x: tf.zeros_like(x))\n",
    ")\n",
    "\n",
    "# We also add lots of dummy embeddings by randomly perturbing\n",
    "# the estimated embeddings for real movies.\n",
    "lots_of_movies_embeddings = tf.data.Dataset.concatenate(\n",
    "    movies.batch(4096).map(model.movie_model),\n",
    "    movies.batch(4096).repeat(1_000)\n",
    "      .map(lambda x: model.movie_model(x))\n",
    "      .map(lambda x: x * tf.random.uniform(tf.shape(x)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8e8a619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x1f8526d16d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brute_force_lots = tfrs.layers.factorized_top_k.BruteForce()\n",
    "brute_force_lots.index_from_dataset(\n",
    "    tf.data.Dataset.zip((lots_of_movies, lots_of_movies_embeddings))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4e91259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommendations: [b\"Kid in King Arthur's Court, A (1995)\"\n",
      " b'Bedknobs and Broomsticks (1971)'\n",
      " b'Homeward Bound: The Incredible Journey (1993)']\n"
     ]
    }
   ],
   "source": [
    "_, titles = brute_force_lots(model.user_model(np.array([\"42\"])), k=3)\n",
    "\n",
    "print(f\"Top recommendations: {titles[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "626d1000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.89 ms ± 379 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _, titles = brute_force_lots(model.user_model(np.array([\"42\"])), k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f24c1b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "The scann library is not present. Please install it using `pip install scann` to use the ScaNN layer.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m scann \u001b[38;5;241m=\u001b[39m \u001b[43mtfrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorized_top_k\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mScaNN\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_reordering_candidates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_leaves_to_search\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\n\u001b[0;32m      4\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m scann\u001b[38;5;241m.\u001b[39mindex_from_dataset(\n\u001b[0;32m      6\u001b[0m     tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mzip((lots_of_movies, lots_of_movies_embeddings))\n\u001b[0;32m      7\u001b[0m )\n",
      "File \u001b[1;32mD:\\InstalledSoftware\\anaconda3\\envs\\python-notebook\\lib\\site-packages\\tensorflow_recommenders\\layers\\factorized_top_k.py:657\u001b[0m, in \u001b[0;36mScaNN.__init__\u001b[1;34m(self, query_model, k, distance_measure, num_leaves, num_leaves_to_search, training_iterations, dimensions_per_block, num_reordering_candidates, parallelize_batch_searches, name)\u001b[0m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(k\u001b[38;5;241m=\u001b[39mk, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _HAVE_SCANN:\n\u001b[1;32m--> 657\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    658\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe scann library is not present. Please install it using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    659\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install scann` to use the ScaNN layer.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_model \u001b[38;5;241m=\u001b[39m query_model\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_k \u001b[38;5;241m=\u001b[39m k\n",
      "\u001b[1;31mImportError\u001b[0m: The scann library is not present. Please install it using `pip install scann` to use the ScaNN layer."
     ]
    }
   ],
   "source": [
    "scann = tfrs.layers.factorized_top_k.ScaNN(\n",
    "    num_reordering_candidates=500,\n",
    "    num_leaves_to_search=30\n",
    ")\n",
    "scann.index_from_dataset(\n",
    "    tf.data.Dataset.zip((lots_of_movies, lots_of_movies_embeddings))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d63b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, titles = scann(model.user_model(np.array([\"42\"])), k=3)\n",
    "\n",
    "print(f\"Top recommendations: {titles[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9518008",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit _, titles = scann(model.user_model(np.array([\"42\"])), k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183aed37",
   "metadata": {},
   "source": [
    "### Evaluating the approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532523c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override the existing streaming candidate source.\n",
    "model.task.factorized_metrics = tfrs.metrics.FactorizedTopK(\n",
    "    candidates=tf.data.Dataset.zip((lots_of_movies, lots_of_movies_embeddings))\n",
    ")\n",
    "# Need to recompile the model for the changes to take effect.\n",
    "model.compile()\n",
    "\n",
    "%time baseline_result = model.evaluate(test.batch(8192), return_dict=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f77a536",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.task.factorized_metrics = tfrs.metrics.FactorizedTopK(\n",
    "    candidates=scann\n",
    ")\n",
    "model.compile()\n",
    "\n",
    "# We can use a much bigger batch size here because ScaNN evaluation\n",
    "# is more memory efficient.\n",
    "%time scann_result = model.evaluate(test.batch(8192), return_dict=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dde5119",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Brute force top-100 accuracy: {baseline_result['factorized_top_k/top_100_categorical_accuracy']:.2f}\")\n",
    "print(f\"ScaNN top-100 accuracy:       {scann_result['factorized_top_k/top_100_categorical_accuracy']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a0b30c",
   "metadata": {},
   "source": [
    "### Deploying the approximate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90f0e307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcatenateDataset element_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lots_of_movies_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58ee6c8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "The scann library is not present. Please install it using `pip install scann` to use the ScaNN layer.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [19], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# We re-index the ScaNN layer to include the user embeddings in the same model.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# This way we can give the saved model raw features and get valid predictions\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# back.\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m scann \u001b[38;5;241m=\u001b[39m \u001b[43mtfrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorized_top_k\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mScaNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_reordering_candidates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m scann\u001b[38;5;241m.\u001b[39mindex_from_dataset(\n\u001b[0;32m      6\u001b[0m     tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mzip((lots_of_movies, lots_of_movies_embeddings))\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Need to call it to set the shapes.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\InstalledSoftware\\anaconda3\\envs\\python-notebook\\lib\\site-packages\\tensorflow_recommenders\\layers\\factorized_top_k.py:657\u001b[0m, in \u001b[0;36mScaNN.__init__\u001b[1;34m(self, query_model, k, distance_measure, num_leaves, num_leaves_to_search, training_iterations, dimensions_per_block, num_reordering_candidates, parallelize_batch_searches, name)\u001b[0m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(k\u001b[38;5;241m=\u001b[39mk, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _HAVE_SCANN:\n\u001b[1;32m--> 657\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    658\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe scann library is not present. Please install it using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    659\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install scann` to use the ScaNN layer.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_model \u001b[38;5;241m=\u001b[39m query_model\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_k \u001b[38;5;241m=\u001b[39m k\n",
      "\u001b[1;31mImportError\u001b[0m: The scann library is not present. Please install it using `pip install scann` to use the ScaNN layer."
     ]
    }
   ],
   "source": [
    "# We re-index the ScaNN layer to include the user embeddings in the same model.\n",
    "# This way we can give the saved model raw features and get valid predictions\n",
    "# back.\n",
    "scann = tfrs.layers.factorized_top_k.ScaNN(model.user_model, num_reordering_candidates=1000)\n",
    "scann.index_from_dataset(\n",
    "    tf.data.Dataset.zip((lots_of_movies, lots_of_movies_embeddings))\n",
    ")\n",
    "\n",
    "# Need to call it to set the shapes.\n",
    "_ = scann(np.array([\"42\"]))\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "    path = os.path.join(tmp, \"model\")\n",
    "    tf.saved_model.save(\n",
    "        scann,\n",
    "        path,\n",
    "        options=tf.saved_model.SaveOptions(namespace_whitelist=[\"Scann\"])\n",
    "    )\n",
    "    loaded = tf.saved_model.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81a99426",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loaded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m _, titles \u001b[38;5;241m=\u001b[39m \u001b[43mloaded\u001b[49m(tf\u001b[38;5;241m.\u001b[39mconstant([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m42\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop recommendations: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtitles[\u001b[38;5;241m0\u001b[39m][:\u001b[38;5;241m3\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loaded' is not defined"
     ]
    }
   ],
   "source": [
    "_, titles = loaded(tf.constant([\"42\"]))\n",
    "\n",
    "print(f\"Top recommendations: {titles[0][:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aaa389",
   "metadata": {},
   "source": [
    "### Tuning ScaNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18342fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process queries in groups of 1000; processing them all at once with brute force\n",
    "# may lead to out-of-memory errors, because processing a batch of q queries against\n",
    "# a size-n dataset takes O(nq) space with brute force.\n",
    "titles_ground_truth = tf.concat([\n",
    "  brute_force_lots(queries, k=10)[1] for queries in\n",
    "  test.batch(1000).map(lambda x: model.user_model(x[\"user_id\"]))\n",
    "], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef061e5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scann' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [23], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m test_flat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(\u001b[38;5;28mlist\u001b[39m(test\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m1000\u001b[39m)\u001b[38;5;241m.\u001b[39mas_numpy_iterator()), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# ScaNN is much more memory efficient and has no problem processing the whole\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# batch of 20000 queries at once.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m _, titles \u001b[38;5;241m=\u001b[39m \u001b[43mscann\u001b[49m(test_flat, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scann' is not defined"
     ]
    }
   ],
   "source": [
    "# Get all user_id's as a 1d tensor of strings\n",
    "test_flat = np.concatenate(list(test.map(lambda x: x[\"user_id\"]).batch(1000).as_numpy_iterator()), axis=0)\n",
    "\n",
    "# ScaNN is much more memory efficient and has no problem processing the whole\n",
    "# batch of 20000 queries at once.\n",
    "_, titles = scann(test_flat, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86639a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recall(ground_truth, approx_results):\n",
    "    return np.mean([\n",
    "        len(np.intersect1d(truth, approx)) / len(truth)\n",
    "        for truth, approx in zip(ground_truth, approx_results)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90cc8e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Recall: {compute_recall(titles_ground_truth, titles):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "382001d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scann' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimeit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-n 1000 scann(np.array([\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m42\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m]), k=10)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\InstalledSoftware\\anaconda3\\envs\\python-notebook\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2364\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2362\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[0;32m   2363\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m-> 2364\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mD:\\InstalledSoftware\\anaconda3\\envs\\python-notebook\\lib\\site-packages\\IPython\\core\\magics\\execution.py:1166\u001b[0m, in \u001b[0;36mExecutionMagics.timeit\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1163\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m time_number \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m:\n\u001b[0;32m   1164\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1166\u001b[0m all_runs \u001b[38;5;241m=\u001b[39m \u001b[43mtimer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepeat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1167\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(all_runs) \u001b[38;5;241m/\u001b[39m number\n\u001b[0;32m   1168\u001b[0m worst \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(all_runs) \u001b[38;5;241m/\u001b[39m number\n",
      "File \u001b[1;32mD:\\InstalledSoftware\\anaconda3\\envs\\python-notebook\\lib\\timeit.py:205\u001b[0m, in \u001b[0;36mTimer.repeat\u001b[1;34m(self, repeat, number)\u001b[0m\n\u001b[0;32m    203\u001b[0m r \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(repeat):\n\u001b[1;32m--> 205\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m     r\u001b[38;5;241m.\u001b[39mappend(t)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[1;32mD:\\InstalledSoftware\\anaconda3\\envs\\python-notebook\\lib\\site-packages\\IPython\\core\\magics\\execution.py:156\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[1;34m(self, number)\u001b[0m\n\u001b[0;32m    154\u001b[0m gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 156\u001b[0m     timing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gcold:\n",
      "File \u001b[1;32m<magic-timeit>:1\u001b[0m, in \u001b[0;36minner\u001b[1;34m(_it, _timer)\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scann' is not defined"
     ]
    }
   ],
   "source": [
    "%timeit -n 1000 scann(np.array([\"42\"]), k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24557ba8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "The scann library is not present. Please install it using `pip install scann` to use the ScaNN layer.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m scann2 \u001b[38;5;241m=\u001b[39m \u001b[43mtfrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorized_top_k\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mScaNN\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_leaves\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_leaves_to_search\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_reordering_candidates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m scann2\u001b[38;5;241m.\u001b[39mindex_from_dataset(\n\u001b[0;32m      7\u001b[0m     tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mzip((lots_of_movies, lots_of_movies_embeddings))\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m     10\u001b[0m _, titles2 \u001b[38;5;241m=\u001b[39m scann2(test_flat, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32mD:\\InstalledSoftware\\anaconda3\\envs\\python-notebook\\lib\\site-packages\\tensorflow_recommenders\\layers\\factorized_top_k.py:657\u001b[0m, in \u001b[0;36mScaNN.__init__\u001b[1;34m(self, query_model, k, distance_measure, num_leaves, num_leaves_to_search, training_iterations, dimensions_per_block, num_reordering_candidates, parallelize_batch_searches, name)\u001b[0m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(k\u001b[38;5;241m=\u001b[39mk, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _HAVE_SCANN:\n\u001b[1;32m--> 657\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    658\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe scann library is not present. Please install it using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    659\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install scann` to use the ScaNN layer.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_model \u001b[38;5;241m=\u001b[39m query_model\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_k \u001b[38;5;241m=\u001b[39m k\n",
      "\u001b[1;31mImportError\u001b[0m: The scann library is not present. Please install it using `pip install scann` to use the ScaNN layer."
     ]
    }
   ],
   "source": [
    "scann2 = tfrs.layers.factorized_top_k.ScaNN(\n",
    "    model.user_model, \n",
    "    num_leaves=1000,\n",
    "    num_leaves_to_search=100,\n",
    "    num_reordering_candidates=1000)\n",
    "scann2.index_from_dataset(\n",
    "    tf.data.Dataset.zip((lots_of_movies, lots_of_movies_embeddings))\n",
    ")\n",
    "\n",
    "_, titles2 = scann2(test_flat, k=10)\n",
    "\n",
    "print(f\"Recall: {compute_recall(titles_ground_truth, titles2):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9fa3506",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scann2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimeit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-n 1000 scann2(np.array([\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m42\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m]), k=10)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\InstalledSoftware\\anaconda3\\envs\\python-notebook\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2364\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2362\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[0;32m   2363\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m-> 2364\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mD:\\InstalledSoftware\\anaconda3\\envs\\python-notebook\\lib\\site-packages\\IPython\\core\\magics\\execution.py:1166\u001b[0m, in \u001b[0;36mExecutionMagics.timeit\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1163\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m time_number \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m:\n\u001b[0;32m   1164\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1166\u001b[0m all_runs \u001b[38;5;241m=\u001b[39m \u001b[43mtimer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepeat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1167\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(all_runs) \u001b[38;5;241m/\u001b[39m number\n\u001b[0;32m   1168\u001b[0m worst \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(all_runs) \u001b[38;5;241m/\u001b[39m number\n",
      "File \u001b[1;32mD:\\InstalledSoftware\\anaconda3\\envs\\python-notebook\\lib\\timeit.py:205\u001b[0m, in \u001b[0;36mTimer.repeat\u001b[1;34m(self, repeat, number)\u001b[0m\n\u001b[0;32m    203\u001b[0m r \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(repeat):\n\u001b[1;32m--> 205\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m     r\u001b[38;5;241m.\u001b[39mappend(t)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[1;32mD:\\InstalledSoftware\\anaconda3\\envs\\python-notebook\\lib\\site-packages\\IPython\\core\\magics\\execution.py:156\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[1;34m(self, number)\u001b[0m\n\u001b[0;32m    154\u001b[0m gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 156\u001b[0m     timing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gcold:\n",
      "File \u001b[1;32m<magic-timeit>:1\u001b[0m, in \u001b[0;36minner\u001b[1;34m(_it, _timer)\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scann2' is not defined"
     ]
    }
   ],
   "source": [
    "%timeit -n 1000 scann2(np.array([\"42\"]), k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f4a7ed4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "The scann library is not present. Please install it using `pip install scann` to use the ScaNN layer.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m scann3 \u001b[38;5;241m=\u001b[39m \u001b[43mtfrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorized_top_k\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mScaNN\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_leaves\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_leaves_to_search\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m70\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_reordering_candidates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m scann3\u001b[38;5;241m.\u001b[39mindex_from_dataset(\n\u001b[0;32m      7\u001b[0m     tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mzip((lots_of_movies, lots_of_movies_embeddings))\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m     10\u001b[0m _, titles3 \u001b[38;5;241m=\u001b[39m scann3(test_flat, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32mD:\\InstalledSoftware\\anaconda3\\envs\\python-notebook\\lib\\site-packages\\tensorflow_recommenders\\layers\\factorized_top_k.py:657\u001b[0m, in \u001b[0;36mScaNN.__init__\u001b[1;34m(self, query_model, k, distance_measure, num_leaves, num_leaves_to_search, training_iterations, dimensions_per_block, num_reordering_candidates, parallelize_batch_searches, name)\u001b[0m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(k\u001b[38;5;241m=\u001b[39mk, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _HAVE_SCANN:\n\u001b[1;32m--> 657\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    658\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe scann library is not present. Please install it using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    659\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install scann` to use the ScaNN layer.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_model \u001b[38;5;241m=\u001b[39m query_model\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_k \u001b[38;5;241m=\u001b[39m k\n",
      "\u001b[1;31mImportError\u001b[0m: The scann library is not present. Please install it using `pip install scann` to use the ScaNN layer."
     ]
    }
   ],
   "source": [
    "scann3 = tfrs.layers.factorized_top_k.ScaNN(\n",
    "    model.user_model,\n",
    "    num_leaves=1000,\n",
    "    num_leaves_to_search=70,\n",
    "    num_reordering_candidates=400)\n",
    "scann3.index_from_dataset(\n",
    "    tf.data.Dataset.zip((lots_of_movies, lots_of_movies_embeddings))\n",
    ")\n",
    "\n",
    "_, titles3 = scann3(test_flat, k=10)\n",
    "print(f\"Recall: {compute_recall(titles_ground_truth, titles3):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0d8407d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scann3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimeit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-n 1000 scann3(np.array([\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m42\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m]), k=10)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\InstalledSoftware\\anaconda3\\envs\\python-notebook\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2364\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2362\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[0;32m   2363\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m-> 2364\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mD:\\InstalledSoftware\\anaconda3\\envs\\python-notebook\\lib\\site-packages\\IPython\\core\\magics\\execution.py:1166\u001b[0m, in \u001b[0;36mExecutionMagics.timeit\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1163\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m time_number \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m:\n\u001b[0;32m   1164\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1166\u001b[0m all_runs \u001b[38;5;241m=\u001b[39m \u001b[43mtimer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepeat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1167\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(all_runs) \u001b[38;5;241m/\u001b[39m number\n\u001b[0;32m   1168\u001b[0m worst \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(all_runs) \u001b[38;5;241m/\u001b[39m number\n",
      "File \u001b[1;32mD:\\InstalledSoftware\\anaconda3\\envs\\python-notebook\\lib\\timeit.py:205\u001b[0m, in \u001b[0;36mTimer.repeat\u001b[1;34m(self, repeat, number)\u001b[0m\n\u001b[0;32m    203\u001b[0m r \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(repeat):\n\u001b[1;32m--> 205\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m     r\u001b[38;5;241m.\u001b[39mappend(t)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[1;32mD:\\InstalledSoftware\\anaconda3\\envs\\python-notebook\\lib\\site-packages\\IPython\\core\\magics\\execution.py:156\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[1;34m(self, number)\u001b[0m\n\u001b[0;32m    154\u001b[0m gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 156\u001b[0m     timing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gcold:\n",
      "File \u001b[1;32m<magic-timeit>:1\u001b[0m, in \u001b[0;36minner\u001b[1;34m(_it, _timer)\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scann3' is not defined"
     ]
    }
   ],
   "source": [
    "%timeit -n 1000 scann3(np.array([\"42\"]), k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbd9f60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
