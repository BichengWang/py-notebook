{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd4570c4",
   "metadata": {},
   "source": [
    "# Listwise ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84547599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a0a7a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_ranking as tfr\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59fbeb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")\n",
    "\n",
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "    \"user_rating\": x[\"user_rating\"],\n",
    "})\n",
    "movies = movies.map(lambda x: x[\"movie_title\"])\n",
    "\n",
    "unique_movie_titles = np.unique(np.concatenate(list(movies.batch(1000))))\n",
    "unique_user_ids = np.unique(np.concatenate(list(ratings.batch(1_000).map(\n",
    "    lambda x: x[\"user_id\"]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02d3fe9",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f1df0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# Split between train and tests sets, as before.\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)\n",
    "\n",
    "# We sample 50 lists for each user for the training data. For each list we\n",
    "# sample 5 movies from the movies the user rated.\n",
    "train = tfrs.examples.movielens.sample_listwise(\n",
    "    train,\n",
    "    num_list_per_user=50,\n",
    "    num_examples_per_list=5,\n",
    "    seed=42\n",
    ")\n",
    "test = tfrs.examples.movielens.sample_listwise(\n",
    "    test,\n",
    "    num_list_per_user=1,\n",
    "    num_examples_per_list=5,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "928205c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_title': <tf.Tensor: shape=(5,), dtype=string, numpy=\n",
      "array([b'Postman, The (1997)', b'Liar Liar (1997)', b'Contact (1997)',\n",
      "       b'Welcome To Sarajevo (1997)',\n",
      "       b'I Know What You Did Last Summer (1997)'], dtype=object)>,\n",
      " 'user_id': <tf.Tensor: shape=(), dtype=string, numpy=b'681'>,\n",
      " 'user_rating': <tf.Tensor: shape=(5,), dtype=float32, numpy=array([4., 5., 1., 4., 1.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "for example in train.take(1):\n",
    "    pprint.pprint(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f31d127",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7138404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingModel(tfrs.Model):\n",
    "\n",
    "    def __init__(self, loss):\n",
    "        super().__init__()\n",
    "        embedding_dimension = 32\n",
    "        # Compute embeddings for users.\n",
    "        self.user_embeddings = tf.keras.Sequential([\n",
    "          tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_user_ids),\n",
    "          tf.keras.layers.Embedding(len(unique_user_ids) + 2, embedding_dimension)\n",
    "        ])\n",
    "        # Compute embeddings for movies.\n",
    "        self.movie_embeddings = tf.keras.Sequential([\n",
    "          tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_movie_titles),\n",
    "          tf.keras.layers.Embedding(len(unique_movie_titles) + 2, embedding_dimension)\n",
    "        ])\n",
    "        # Compute predictions.\n",
    "        self.score_model = tf.keras.Sequential([\n",
    "          # Learn multiple dense layers.\n",
    "          tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "          tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "          # Make rating predictions in the final layer.\n",
    "          tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "        self.task = tfrs.tasks.Ranking(\n",
    "          loss=loss,\n",
    "          metrics=[\n",
    "            tfr.keras.metrics.NDCGMetric(name=\"ndcg_metric\"),\n",
    "            tf.keras.metrics.RootMeanSquaredError()\n",
    "          ]\n",
    "        )\n",
    "        \n",
    "    def call(self, features):\n",
    "        # We first convert the id features into embeddings.\n",
    "        # User embeddings are a [batch_size, embedding_dim] tensor.\n",
    "        user_embeddings = self.user_embeddings(features[\"user_id\"])\n",
    "        # Movie embeddings are a [batch_size, num_movies_in_list, embedding_dim]\n",
    "        # tensor.\n",
    "        movie_embeddings = self.movie_embeddings(features[\"movie_title\"])\n",
    "        # We want to concatenate user embeddings with movie emebeddings to pass\n",
    "        # them into the ranking model. To do so, we need to reshape the user\n",
    "        # embeddings to match the shape of movie embeddings.\n",
    "        list_length = features[\"movie_title\"].shape[1]\n",
    "        user_embedding_repeated = tf.repeat(\n",
    "            tf.expand_dims(user_embeddings, 1), [list_length], axis=1)\n",
    "        # Once reshaped, we concatenate and pass into the dense layers to generate\n",
    "        # predictions.\n",
    "        concatenated_embeddings = tf.concat(\n",
    "            [user_embedding_repeated, movie_embeddings], 2)\n",
    "        return self.score_model(concatenated_embeddings)\n",
    "    \n",
    "    def compute_loss(self, features, training=False):\n",
    "        labels = features.pop(\"user_rating\")\n",
    "        scores = self(features)\n",
    "        return self.task(\n",
    "            labels=labels,\n",
    "            predictions=tf.squeeze(scores, axis=-1),\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e8969e",
   "metadata": {},
   "source": [
    "### Training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26cdff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "\n",
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953acea1",
   "metadata": {},
   "source": [
    "#### Mean squared error model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03489538",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_model = RankingModel(tf.keras.losses.MeanSquaredError())\n",
    "mse_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0be27fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1329a1f56a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_model.fit(cached_train, epochs=epochs, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c59fd3",
   "metadata": {},
   "source": [
    "#### Pairwise hinge loss model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbf4252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hinge_model = RankingModel(tfr.keras.losses.PairwiseHingeLoss())\n",
    "hinge_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93e42855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1329a175f40>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hinge_model.fit(cached_train, epochs=epochs, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb1d5de",
   "metadata": {},
   "source": [
    "#### Listwise model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d967562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "listwise_model = RankingModel(tfr.keras.losses.ListMLELoss())\n",
    "listwise_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1383d315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1329a2d77c0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listwise_model.fit(cached_train, epochs=epochs, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9157c0fd",
   "metadata": {},
   "source": [
    "### Comparing the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52a84739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 914ms/step - ndcg_metric: 0.9060 - root_mean_squared_error: 0.9783 - loss: 0.9570 - regularization_loss: 0.0000e+00 - total_loss: 0.9570\n",
      "NDCG of the MSE Model: 0.9060\n"
     ]
    }
   ],
   "source": [
    "mse_model_result = mse_model.evaluate(cached_test, return_dict=True)\n",
    "print(\"NDCG of the MSE Model: {:.4f}\".format(mse_model_result[\"ndcg_metric\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf09db2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 960ms/step - ndcg_metric: 0.9061 - root_mean_squared_error: 2.8635 - loss: 1.0196 - regularization_loss: 0.0000e+00 - total_loss: 1.0196\n",
      "NDCG of the pairwise hinge loss model: 0.9061\n"
     ]
    }
   ],
   "source": [
    "hinge_model_result = hinge_model.evaluate(cached_test, return_dict=True)\n",
    "print(\"NDCG of the pairwise hinge loss model: {:.4f}\".format(hinge_model_result[\"ndcg_metric\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "303f5131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 997ms/step - ndcg_metric: 0.9066 - root_mean_squared_error: 3.6482 - loss: 4.5414 - regularization_loss: 0.0000e+00 - total_loss: 4.5414\n",
      "NDCG of the ListMLE model: 0.9066\n"
     ]
    }
   ],
   "source": [
    "listwise_model_result = listwise_model.evaluate(cached_test, return_dict=True)\n",
    "print(\"NDCG of the ListMLE model: {:.4f}\".format(listwise_model_result[\"ndcg_metric\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4833d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
