{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sigmoid = 1 / 1 + exp(-z)\n",
    "\n",
    "Prob(Y=1|X) = sigmoid(z)\n",
    "\n",
    "log-loss / cross-entropy loss\n",
    "\n",
    "loss(W) = -1/m sum(y ln Prob + (1 - y) ln (1 - Prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, lr = 0.01, max_epoch = 1000, tol = 1e-4):\n",
    "        self.lr = lr\n",
    "        self.max_epoch = max_epoch\n",
    "        self.tol = tol\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        \n",
    "    def _init_weights(self, feature_num):\n",
    "        self.w = np.random.rand(feature_num)\n",
    "        self.b = np.random.rand(1)\n",
    "        \n",
    "    def _loss(self, y, y_pred):\n",
    "        return -np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n",
    "    \n",
    "    def _weights_update(self, X, y, y_pred):\n",
    "        sample_num = X.shape[0]\n",
    "        dw = np.dot(X.T, y_pred - y) / sample_num\n",
    "        db = np.mean(y_pred - y)\n",
    "        self.w -= self.lr * dw\n",
    "        self.b -= self.lr * db\n",
    "        \n",
    "    def _sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        sample_num, feature_num = X.shape\n",
    "        self._init_weights(feature_num)\n",
    "        for i in range(self.max_epoch):\n",
    "            y_pred = self.predict(X)\n",
    "            loss = self._loss(y, y_pred)\n",
    "            if loss < self.tol:\n",
    "                break\n",
    "            self._weights_update(X, y, y_pred)\n",
    "        return\n",
    "    \n",
    "    def predict(self, X):\n",
    "        z = np.dot(X, self.w) + self.b\n",
    "        y_pred = self._sigmoid(z)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95002217 0.97335034]\n"
     ]
    }
   ],
   "source": [
    "# create sample dataset\n",
    "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]])\n",
    "y = np.array([0, 0, 1, 1, 1])\n",
    "\n",
    "# initialize logistic regression model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# train model on sample dataset\n",
    "lr.fit(X, y)\n",
    "\n",
    "# make predictions on new data\n",
    "X_new = np.array([[6, 7], [7, 8]])\n",
    "y_pred = lr.predict(X_new)\n",
    "\n",
    "print(y_pred)  # [1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Follow Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. regularization:   \n",
    "\n",
    "Regularization can help prevent overfitting and improve the generalization performance of the model. You could add L1 or L2 regularization to the cost function and adjust the regularization strength with a hyperparameter. Here's an example of how to add L2 regularization to the code;\n",
    "\n",
    "\n",
    "b. sophisticated optimization algorithm:   \n",
    "\n",
    "Gradient descent is a simple and effective optimization algorithm, but it may not be the most efficient or accurate for large or complex datasets. You could try using a more sophisticated algorithm, such as stochastic gradient descent (SGD), mini-batch SGD, or Adam, which can converge faster and find better optima. Here's an example of how to use mini-batch SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class CustomLogisticRegression(LogisticRegression):\n",
    "    def __init__(self, lr=0.01, max_epoch=1000, tol = 1e-4, regularization='l2', reg_strength=0.1, batch_size=32):\n",
    "        super().__init__(lr, max_epoch, tol)\n",
    "        self.regularization = regularization\n",
    "        self.reg_strength = reg_strength\n",
    "        self.batch_size = batch_size\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        \n",
    "    def _loss(self, y, y_pred):\n",
    "        sample_num = y.shape[0]\n",
    "        loss = -np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n",
    "        if self.regularization == 'l1':\n",
    "            loss += self.reg_strength * np.sum(np.abs(self.w))\n",
    "        elif self.regularization == 'l2':\n",
    "            loss += self.reg_strength * np.sum(self.w ** 2)\n",
    "        return loss\n",
    "    \n",
    "    def _weights_update(self, X, y, y_pred):\n",
    "        sample_num = X.shape[0]\n",
    "        dw = np.dot(X.T, (y_pred - y)) / sample_num\n",
    "        db = np.mean(y_pred - y)\n",
    "        if self.regularization == 'l1':\n",
    "            dw += self.reg_strength * np.sign(self.w)\n",
    "        elif self.regularization == 'l2':\n",
    "            dw += self.reg_strength * 2 * self.w\n",
    "        self.w -= self.lr * dw\n",
    "        self.b -= self.lr * db\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        sample_num, feature_num = X.shape\n",
    "        self._init_weights(feature_num)\n",
    "        \n",
    "        batch_num = sample_num // self.batch_size\n",
    "        for i in range(self.max_epoch):\n",
    "            for j in range(batch_num):\n",
    "                batch_indices = np.random.choice(sample_num, batch_num, replace=False)\n",
    "                X_batch, y_batch = X[batch_indices], y[batch_indices]\n",
    "                y_pred_batch = self.predict(X_batch)\n",
    "                loss = self._loss(y_batch, y_pred_batch)\n",
    "                if loss < self.tol:\n",
    "                    break\n",
    "                self._weights_update(X_batch, y_batch, y_pred_batch)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization: You can choose between L1 or L2 regularization by setting the regularization parameter to either 'l1' or 'l2', and adjust the regularization strength with the reg_strength parameter.\n",
    "\n",
    "Mini-batch stochastic gradient descent: The model uses mini-batch SGD (instead of simple gradient descent) to update the weights and bias, which can converge faster and find better optima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96960211 0.98596092]\n"
     ]
    }
   ],
   "source": [
    "# create sample dataset\n",
    "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]])\n",
    "y = np.array([0, 0, 1, 1, 1])\n",
    "\n",
    "# initialize logistic regression model\n",
    "lr = CustomLogisticRegression(lr=0.01, max_epoch=1000, regularization='l2', reg_strength=0.1, batch_size=2)\n",
    "\n",
    "# train model on sample dataset\n",
    "lr.fit(X, y)\n",
    "\n",
    "# make predictions on new data\n",
    "X_new = np.array([[6, 7], [7, 8]])\n",
    "y_pred = lr.predict(X_new)\n",
    "\n",
    "print(y_pred)  # [1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is difficult to visualize logistic regression since it is a high-dimensional problem. However, we can visualize the decision boundary of a logistic regression model for a two-dimensional dataset.\n",
    "\n",
    "Here's an example of how to visualize the decision boundary of the LogisticRegression class on a 2D dataset using the matplotlib library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create 2D dataset\n",
    "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]])\n",
    "y = np.array([0, 0, 1, 1, 1])\n",
    "\n",
    "# initialize logistic regression model\n",
    "lr = CustomLogisticRegression(lr=0.01, max_epoch=1000, regularization='l2', reg_strength=0.1, batch_size=2)\n",
    "\n",
    "# train model on dataset\n",
    "lr.fit(X, y)\n",
    "\n",
    "# plot decision boundary\n",
    "x1 = np.linspace(0, 6, 100)\n",
    "x2 = np.linspace(0, 8, 100)\n",
    "xx, yy = np.meshgrid(x1, x2)\n",
    "Z = lr.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.8)\n",
    "\n",
    "# plot data points\n",
    "plt.scatter(X[:,0], X[:,1], c=y, cmap=plt.cm.Spectral)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Dimension Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F(X) = X W\n",
    "\n",
    "H(X) = sigmoid(F(X))\n",
    "\n",
    "Cost = - 1/n sum(Y log(H(X)) + (1 - Y) log (1 - H(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "n, k, p=100, 8, 3 \n",
    "X=np.random.random([n,k])\n",
    "W=np.random.random([k,p])\n",
    "y=np.random.randint(p, size=(1,n))\n",
    "Y=np.zeros((n,p))\n",
    "Y[np.arange(n), y]=1\n",
    "\n",
    "max_itr=5000\n",
    "alpha=0.01\n",
    "Lambda=0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient:   \n",
    "X.T (H(X) - Y) + 2 lambda W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F(x)= w[0]*x + w[1]\n",
    "def F(X, W):\n",
    "    return np.matmul(X,W)\n",
    "\n",
    "def H(F):\n",
    "    return 1/(1+np.exp(-F))\n",
    "\n",
    "def cost(Y_est, Y):\n",
    "    E= - (1/n) * (np.sum(Y*np.log(Y_est) + (1-Y)*np.log(1-Y_est)))  + np.linalg.norm(W,2)\n",
    "    return E, np.sum(np.argmax(Y_est,1)==y)/n\n",
    "\n",
    "def gradient(Y_est, Y, X):\n",
    "    return (1/n) * np.matmul(X.T, (Y_est - Y) ) + Lambda* 2* W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(W, X, Y, alpha, max_itr):\n",
    "    for i in range(max_itr):\n",
    "        \n",
    "        F_x=F(X,W)\n",
    "        Y_est=H(F_x)\n",
    "        E, c= cost(Y_est, Y)\n",
    "        Wg=gradient(Y_est, Y, X)\n",
    "        W=W - alpha * Wg\n",
    "        if i%1000==0:\n",
    "            print(E, c)\n",
    "        \n",
    "    return W, Y_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.092899559385625 0.45\n",
      "3.945607363106942 0.52\n",
      "3.9447706083599234 0.5\n",
      "3.9445279912579565 0.53\n",
      "3.9445998856334037 0.53\n"
     ]
    }
   ],
   "source": [
    "X=np.concatenate( (X, np.ones((n,1))), axis=1 ) \n",
    "W=np.concatenate( (W, np.random.random((1,p)) ), axis=0 )\n",
    "\n",
    "W, Y_est = fit(W, X, Y, alpha, max_itr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
